{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0c5d8d",
   "metadata": {},
   "source": [
    "### MLP 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ed1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(MultilayerPerceptron,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \n",
    "#         relu 활성화 함수를 통해 비선형성을 추가\n",
    "        intermediate = F.relu(self.fc1(x_in))\n",
    "        output = self.fc2(intermediate)\n",
    "        \n",
    "#         softmax 적용여부 \n",
    "        if apply_softmax:\n",
    "#           dim = 행렬의 각 행에 대해 소프트맥스 함수를 적용\n",
    "            output = F.softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3f39e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# example1\n",
    "\n",
    "input_dim = 3\n",
    "hidden_dim = 100\n",
    "output_dim = 4\n",
    "\n",
    "mlp = MultilayerPerceptron(input_dim,hidden_dim,output_dim)\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbb0140",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962715ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nationality</th>\n",
       "      <th>nationality_index</th>\n",
       "      <th>split</th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Totah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Abboud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Fakhoury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Srour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Sayegh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Dinh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Phung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Quang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Vu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Ha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nationality  nationality_index  split   surname\n",
       "0          Arabic                 15  train     Totah\n",
       "1          Arabic                 15  train    Abboud\n",
       "2          Arabic                 15  train  Fakhoury\n",
       "3          Arabic                 15  train     Srour\n",
       "4          Arabic                 15  train    Sayegh\n",
       "...           ...                ...    ...       ...\n",
       "10975  Vietnamese                 11   test      Dinh\n",
       "10976  Vietnamese                 11   test     Phung\n",
       "10977  Vietnamese                 11   test     Quang\n",
       "10978  Vietnamese                 11   test        Vu\n",
       "10979  Vietnamese                 11   test        Ha\n",
       "\n",
       "[10980 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"surnames_with_splits.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b1afc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nationality\n",
       "English       2972\n",
       "Russian       2373\n",
       "Arabic        1603\n",
       "Japanese       775\n",
       "Italian        600\n",
       "German         576\n",
       "Czech          414\n",
       "Spanish        258\n",
       "Dutch          236\n",
       "French         229\n",
       "Chinese        220\n",
       "Irish          183\n",
       "Greek          156\n",
       "Polish         120\n",
       "Korean          77\n",
       "Scottish        75\n",
       "Vietnamese      58\n",
       "Portuguese      55\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['nationality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f706d137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    7680\n",
       "test     1660\n",
       "val      1640\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f63e53",
   "metadata": {},
   "source": [
    "### 데이터 split(train/valid/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2795b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 다시 train/valid/test로 나눠줌\n",
    "\n",
    "# train 데이터 \n",
    "train_df = df[df.split=='train']\n",
    "train_size = len(train_df)\n",
    "\n",
    "# valid 데이터 \n",
    "val_df = df[df.split=='val']\n",
    "val_size = len(val_df)\n",
    "\n",
    "# test 데이터 \n",
    "test_df = df[df.split=='test']\n",
    "test_size = len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf85816",
   "metadata": {},
   "source": [
    "### 2. Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9498e793",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "# Counter()를 통해 어떤 단어가 얼만큼의 횟수로 들어있는지를 알 수 있다.\n",
    "word_counts = Counter()\n",
    "for name_text in df.surname:\n",
    "#     print(review)\n",
    "    for word in name_text.split(\" \"):\n",
    "        # word가 .(구두점,punctuation)이 아닐 경우 word에 추가\n",
    "        if word not in string.punctuation:\n",
    "            word_counts[word] += 1\n",
    "\n",
    "# word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1141fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_unk=True를 하면 '<UNK>': 0 토큰을 추가해줌 !\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, add_unk=False):\n",
    "        self.token_to_idx = {}\n",
    "        self.idx_to_token = {}\n",
    "    \n",
    "#         \"UNK\" 토큰이 추가되지 않는 경우에는 -1로 설정,\n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "#         \"UNK\" 토큰이 추가될 경우에는 UNK에 해당하는 인덱스로 설정,\n",
    "            self.unk_index = self.add_token('<UNK>') \n",
    "\n",
    "    def add_token(self, token):\n",
    "        \n",
    "#       만약 해당 토큰이 있으면 토큰 idx만 return\n",
    "        if token in self.token_to_idx:\n",
    "            index = self.token_to_idx[token]\n",
    "            \n",
    "#       만약 해당 토큰이 없으면 새로운 토큰 만들어줌\n",
    "        else:\n",
    "            index = len(self.token_to_idx)\n",
    "            self.token_to_idx[token] = index\n",
    "            self.idx_to_token[index] = token\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac347e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff 보다 수가 많은 단어만 vocab에 추가\n",
    "cutoff = 0\n",
    "\n",
    "# Vocabulary 객체 생성\n",
    "# cutoff보다 작으면 unk토큰으로 지정해줄 것이기 때문에 True\n",
    "name_vocab = Vocabulary(add_unk=True)\n",
    "\n",
    "# word_counts.items() -> ex) ('all', 24160)\n",
    "for word, count in word_counts.items():\n",
    "    if count > cutoff:\n",
    "        name_vocab.add_token(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51f439e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0,\n",
       " 'Totah': 1,\n",
       " 'Abboud': 2,\n",
       " 'Fakhoury': 3,\n",
       " 'Srour': 4,\n",
       " 'Sayegh': 5,\n",
       " 'Cham': 6,\n",
       " 'Haik': 7,\n",
       " 'Kattan': 8,\n",
       " 'Khouri': 9,\n",
       " 'Antoun': 10,\n",
       " 'Wasem': 11,\n",
       " 'Seif': 12,\n",
       " 'Guirguis': 13,\n",
       " 'Sarkis': 14,\n",
       " 'Said': 15,\n",
       " 'Malouf': 16,\n",
       " 'Bishara': 17,\n",
       " 'Ganim': 18,\n",
       " 'Baz': 19,\n",
       " 'Assaf': 20,\n",
       " 'Nader': 21,\n",
       " 'Isa': 22,\n",
       " 'Awad': 23,\n",
       " 'Deeb': 24,\n",
       " 'Kanaan': 25,\n",
       " 'Quraishi': 26,\n",
       " 'Atiyeh': 27,\n",
       " 'Boutros': 28,\n",
       " 'Sabbagh': 29,\n",
       " 'Mustafa': 30,\n",
       " 'Mansour': 31,\n",
       " 'Hadad': 32,\n",
       " 'Salib': 33,\n",
       " 'Sabbag': 34,\n",
       " 'Kassab': 35,\n",
       " 'Moghadam': 36,\n",
       " 'Najjar': 37,\n",
       " 'Gerges': 38,\n",
       " 'Safar': 39,\n",
       " 'Mifsud': 40,\n",
       " 'Shalhoub': 41,\n",
       " 'Koury': 42,\n",
       " 'Kalb': 43,\n",
       " 'Harb': 44,\n",
       " 'Toma': 45,\n",
       " 'Maalouf': 46,\n",
       " 'Kouri': 47,\n",
       " 'Shadid': 48,\n",
       " 'Dagher': 49,\n",
       " 'Tahan': 50,\n",
       " 'Bahar': 51,\n",
       " 'Boulos': 52,\n",
       " 'Attia': 53,\n",
       " 'Amari': 54,\n",
       " 'Naser': 55,\n",
       " 'Bazzi': 56,\n",
       " 'Bata': 57,\n",
       " 'Shamoon': 58,\n",
       " 'Hanania': 59,\n",
       " 'Masih': 60,\n",
       " 'Halabi': 61,\n",
       " 'Saliba': 62,\n",
       " 'Antar': 63,\n",
       " 'Qureshi': 64,\n",
       " 'Kassis': 65,\n",
       " 'Sarraf': 66,\n",
       " 'Essa': 67,\n",
       " 'Touma': 68,\n",
       " 'Maroun': 69,\n",
       " 'Almasi': 70,\n",
       " 'Ganem': 71,\n",
       " 'Bitar': 72,\n",
       " 'Khoury': 73,\n",
       " 'Aswad': 74,\n",
       " 'Sleiman': 75,\n",
       " 'Handal': 76,\n",
       " 'Abadi': 77,\n",
       " 'Naifeh': 78,\n",
       " 'Shammas': 79,\n",
       " 'Tuma': 80,\n",
       " 'Shamon': 81,\n",
       " 'Botros': 82,\n",
       " 'Basara': 83,\n",
       " 'Hajjar': 84,\n",
       " 'Mikhail': 85,\n",
       " 'Rahal': 86,\n",
       " 'Ghanem': 87,\n",
       " 'Baba': 88,\n",
       " 'Haddad': 89,\n",
       " 'Hakimi': 90,\n",
       " 'Asghar': 91,\n",
       " 'Maloof': 92,\n",
       " 'Nazari': 93,\n",
       " 'Gaber': 94,\n",
       " 'Zogby': 95,\n",
       " 'Arian': 96,\n",
       " 'Morcos': 97,\n",
       " 'Nassar': 98,\n",
       " 'Tannous': 99,\n",
       " 'Ghannam': 100,\n",
       " 'Ba': 101,\n",
       " 'Asker': 102,\n",
       " 'Daher': 103,\n",
       " 'Shamoun': 104,\n",
       " 'Nahas': 105,\n",
       " 'Issa': 106,\n",
       " 'Samaha': 107,\n",
       " 'Asfour': 108,\n",
       " 'Hor': 109,\n",
       " 'Fung': 110,\n",
       " 'Mui': 111,\n",
       " 'Kong': 112,\n",
       " 'Nao': 113,\n",
       " 'Ruan': 114,\n",
       " 'Bai': 115,\n",
       " 'Zhao': 116,\n",
       " 'Yee': 117,\n",
       " 'Yau': 118,\n",
       " 'Woo': 119,\n",
       " 'Min': 120,\n",
       " 'Wan': 121,\n",
       " 'Qiao': 122,\n",
       " 'Zong': 123,\n",
       " 'Sui': 124,\n",
       " 'Zhu': 125,\n",
       " 'Joe': 126,\n",
       " 'Chieu': 127,\n",
       " 'Che': 128,\n",
       " 'Won': 129,\n",
       " 'Tsang': 130,\n",
       " 'Wei': 131,\n",
       " 'Shu': 132,\n",
       " 'Eng': 133,\n",
       " 'Lau': 134,\n",
       " 'Jiang': 135,\n",
       " 'Zeng': 136,\n",
       " 'Jia': 137,\n",
       " 'Dong': 138,\n",
       " 'Zhang': 139,\n",
       " 'Tao': 140,\n",
       " 'Guan': 141,\n",
       " 'Niu': 142,\n",
       " 'Nie': 143,\n",
       " 'Ou-Yang': 144,\n",
       " 'Loh': 145,\n",
       " 'Huan': 146,\n",
       " 'Bing': 147,\n",
       " 'Chew': 148,\n",
       " 'Khu': 149,\n",
       " 'Feng': 150,\n",
       " 'Shang': 151,\n",
       " 'Cheng': 152,\n",
       " 'Hua': 153,\n",
       " 'Bian': 154,\n",
       " 'Luo': 155,\n",
       " 'Chan': 156,\n",
       " 'Ban': 157,\n",
       " 'Lai': 158,\n",
       " 'Pang': 159,\n",
       " 'Au-Yong': 160,\n",
       " 'Ran': 161,\n",
       " 'Siew': 162,\n",
       " 'Dai': 163,\n",
       " 'Long': 164,\n",
       " 'Yun': 165,\n",
       " 'Chong': 166,\n",
       " 'Fei': 167,\n",
       " 'Tong': 168,\n",
       " 'Hao': 169,\n",
       " 'She': 170,\n",
       " 'Shen': 171,\n",
       " 'Shui': 172,\n",
       " 'Yue': 173,\n",
       " 'You': 174,\n",
       " 'Chu': 175,\n",
       " 'Xing': 176,\n",
       " 'Tai': 177,\n",
       " 'Chang': 178,\n",
       " 'Thean': 179,\n",
       " 'Rao': 180,\n",
       " 'Pian': 181,\n",
       " 'Kwong': 182,\n",
       " 'Zhou': 183,\n",
       " 'Hew': 184,\n",
       " 'Wang': 185,\n",
       " 'Thien': 186,\n",
       " 'Seah': 187,\n",
       " 'Jiao': 188,\n",
       " 'Tse': 189,\n",
       " 'Ang': 190,\n",
       " 'Zhi': 191,\n",
       " 'Lam': 192,\n",
       " 'Ying': 193,\n",
       " 'Cen': 194,\n",
       " 'Tso': 195,\n",
       " 'Ming': 196,\n",
       " 'Bei': 197,\n",
       " 'Kan': 198,\n",
       " 'Yep': 199,\n",
       " 'Ow-Yang': 200,\n",
       " 'Huang': 201,\n",
       " 'Mei': 202,\n",
       " 'Xian': 203,\n",
       " 'Deng': 204,\n",
       " 'Yap': 205,\n",
       " 'Guang': 206,\n",
       " 'Mah': 207,\n",
       " 'Tow': 208,\n",
       " 'Shan': 209,\n",
       " 'Qin': 210,\n",
       " 'Chen': 211,\n",
       " 'Lew': 212,\n",
       " 'Juan': 213,\n",
       " 'Fan': 214,\n",
       " 'Gauk': 215,\n",
       " 'Pan': 216,\n",
       " 'Jian': 217,\n",
       " 'Law': 218,\n",
       " 'Zou': 219,\n",
       " 'Gong': 220,\n",
       " 'Song': 221,\n",
       " 'See': 222,\n",
       " 'Ping': 223,\n",
       " 'Liang': 224,\n",
       " 'Jue': 225,\n",
       " 'Kwan': 226,\n",
       " 'Foong': 227,\n",
       " 'Kwei': 228,\n",
       " 'Zhai': 229,\n",
       " 'Xie': 230,\n",
       " 'Qiu': 231,\n",
       " 'Xiang': 232,\n",
       " 'Lu:': 233,\n",
       " 'Huie': 234,\n",
       " 'Kui': 235,\n",
       " 'Zha': 236,\n",
       " 'Xin': 237,\n",
       " 'Quan': 238,\n",
       " 'Ding': 239,\n",
       " 'Qian': 240,\n",
       " 'Yin': 241,\n",
       " 'Que': 242,\n",
       " 'Xun': 243,\n",
       " 'Lang': 244,\n",
       " 'Duan': 245,\n",
       " 'Seow': 246,\n",
       " 'Siu': 247,\n",
       " 'Yuan': 248,\n",
       " 'Shuo': 249,\n",
       " 'Kang': 250,\n",
       " 'Huo': 251,\n",
       " 'Zang': 252,\n",
       " 'Jiu': 253,\n",
       " 'Zhan': 254,\n",
       " 'Man': 255,\n",
       " 'Yang': 256,\n",
       " 'Shao': 257,\n",
       " 'Cui': 258,\n",
       " 'Khoo': 259,\n",
       " 'Xiao': 260,\n",
       " 'Cai': 261,\n",
       " 'Tsen': 262,\n",
       " 'Lian': 263,\n",
       " 'Gou': 264,\n",
       " 'Wong': 265,\n",
       " 'Hui': 266,\n",
       " 'Tang': 267,\n",
       " 'Gwock': 268,\n",
       " 'Miao': 269,\n",
       " 'Shaw': 270,\n",
       " 'Liu': 271,\n",
       " 'Sum': 272,\n",
       " 'Cheung': 273,\n",
       " 'Sze': 274,\n",
       " 'Zhui': 275,\n",
       " 'Cong': 276,\n",
       " 'Kau': 277,\n",
       " 'Zhen': 278,\n",
       " 'Jing': 279,\n",
       " 'Rang': 280,\n",
       " 'Mao': 281,\n",
       " 'Shuai': 282,\n",
       " 'Cuan': 283,\n",
       " 'Rong': 284,\n",
       " 'Shi': 285,\n",
       " 'Zhong': 286,\n",
       " 'Zhuo': 287,\n",
       " 'Chi': 288,\n",
       " 'Yan': 289,\n",
       " 'Han': 290,\n",
       " 'Gai': 291,\n",
       " 'Bao': 292,\n",
       " 'Xue': 293,\n",
       " 'Jin': 294,\n",
       " 'Cao': 295,\n",
       " 'Lim': 296,\n",
       " 'Tze': 297,\n",
       " 'Mar': 298,\n",
       " 'Yao': 299,\n",
       " 'Wen': 300,\n",
       " 'Gim': 301,\n",
       " 'Zhuan': 302,\n",
       " 'Ling': 303,\n",
       " 'Lin': 304,\n",
       " 'Teng': 305,\n",
       " 'Rui': 306,\n",
       " 'Dan': 307,\n",
       " 'Bui': 308,\n",
       " 'Guo': 309,\n",
       " 'Gan': 310,\n",
       " 'Hang': 311,\n",
       " 'Chai': 312,\n",
       " 'Kuang': 313,\n",
       " 'Jedlicka': 314,\n",
       " 'Koliha': 315,\n",
       " 'Khork': 316,\n",
       " 'Kucera': 317,\n",
       " 'Schneider': 318,\n",
       " 'Dolezal': 319,\n",
       " 'Rumisek': 320,\n",
       " 'Heidl': 321,\n",
       " 'Gabrisova': 322,\n",
       " 'Cermak': 323,\n",
       " 'Kazimor': 324,\n",
       " 'Nowak': 325,\n",
       " 'Alt': 326,\n",
       " 'Bock': 327,\n",
       " 'Urbanek1': 328,\n",
       " 'Prehatney': 329,\n",
       " 'Stotzky': 330,\n",
       " 'Ballaltick': 331,\n",
       " 'Skala': 332,\n",
       " 'Zak': 333,\n",
       " 'Janca': 334,\n",
       " 'Hajkova': 335,\n",
       " 'Herodes': 336,\n",
       " 'Hiorvst': 337,\n",
       " 'Matejka': 338,\n",
       " 'Prill': 339,\n",
       " 'Charlott': 340,\n",
       " 'Sappe': 341,\n",
       " 'Finferovy': 342,\n",
       " 'Riha': 343,\n",
       " 'Chicken': 344,\n",
       " 'Svotak': 345,\n",
       " 'Bartonova': 346,\n",
       " 'Kolacny': 347,\n",
       " 'Cerny': 348,\n",
       " 'Korycansky': 349,\n",
       " 'Vlach': 350,\n",
       " 'Borovski': 351,\n",
       " 'Snelker': 352,\n",
       " 'Paisar': 353,\n",
       " 'Till': 354,\n",
       " 'Cerda': 355,\n",
       " 'Kessel': 356,\n",
       " 'Psik': 357,\n",
       " 'Geryk': 358,\n",
       " 'Kesl': 359,\n",
       " 'MonkoAustria': 360,\n",
       " 'Okenfuss': 361,\n",
       " 'Furtsch': 362,\n",
       " 'Srda': 363,\n",
       " 'Antonowitz': 364,\n",
       " 'Havlatova': 365,\n",
       " 'Hanzlik': 366,\n",
       " 'Homulka': 367,\n",
       " 'Pitterman': 368,\n",
       " 'Holan': 369,\n",
       " 'Skokan': 370,\n",
       " 'Ponec': 371,\n",
       " 'Seger': 372,\n",
       " 'Dinko': 373,\n",
       " 'Trampota': 374,\n",
       " 'Fenyo': 375,\n",
       " 'Pfeifer': 376,\n",
       " 'Krupala': 377,\n",
       " 'Pawlak': 378,\n",
       " 'Janoch': 379,\n",
       " 'Jirku': 380,\n",
       " 'Markytan': 381,\n",
       " 'Stupka': 382,\n",
       " 'Klimes': 383,\n",
       " 'Havlice': 384,\n",
       " 'Cvacek': 385,\n",
       " 'Glockl': 386,\n",
       " 'Jaluvka': 387,\n",
       " 'Sponer': 388,\n",
       " 'Hartl': 389,\n",
       " 'Muhlbauer': 390,\n",
       " 'Mozzis': 391,\n",
       " 'Hajicek': 392,\n",
       " 'Peary': 393,\n",
       " 'Tejc': 394,\n",
       " 'Grabski': 395,\n",
       " 'Grygarova': 396,\n",
       " 'Staska': 397,\n",
       " 'Kruessel': 398,\n",
       " 'Pinter': 399,\n",
       " 'Vaculova': 400,\n",
       " 'Zaruba': 401,\n",
       " 'Geier': 402,\n",
       " 'Abl': 403,\n",
       " 'Cernochova': 404,\n",
       " 'Faltysek': 405,\n",
       " 'Colling': 406,\n",
       " 'Mudra': 407,\n",
       " 'Savchak': 408,\n",
       " 'Krhovsky': 409,\n",
       " 'Opizka': 410,\n",
       " 'Navrkal': 411,\n",
       " 'Pavlicka': 412,\n",
       " 'Skomicka': 413,\n",
       " 'Demall': 414,\n",
       " 'Slejtr': 415,\n",
       " 'Nemec': 416,\n",
       " 'Trampotova': 417,\n",
       " 'Zwolenksy': 418,\n",
       " 'Hajek': 419,\n",
       " 'Chalupka': 420,\n",
       " 'Ludwig': 421,\n",
       " 'Janicek': 422,\n",
       " 'Entler': 423,\n",
       " 'Pillar': 424,\n",
       " 'Krivan': 425,\n",
       " 'Pavlu': 426,\n",
       " 'Egr': 427,\n",
       " 'Koma': 428,\n",
       " 'Purdes': 429,\n",
       " 'Kupfel': 430,\n",
       " 'Dehmel': 431,\n",
       " 'Weineltk': 432,\n",
       " 'Slivka': 433,\n",
       " 'Votke': 434,\n",
       " 'Katschker': 435,\n",
       " 'Finfera': 436,\n",
       " 'Rezac': 437,\n",
       " 'Jindra': 438,\n",
       " 'Kouba': 439,\n",
       " 'Zajicek': 440,\n",
       " 'Holub': 441,\n",
       " 'Pellar': 442,\n",
       " 'Dempko': 443,\n",
       " 'Krivolavy': 444,\n",
       " 'Neusser': 445,\n",
       " 'Samz': 446,\n",
       " 'Bacon': 447,\n",
       " 'Wilchek': 448,\n",
       " 'Bohac': 449,\n",
       " 'Plisko': 450,\n",
       " 'Victor': 451,\n",
       " 'Sip': 452,\n",
       " 'Klemper': 453,\n",
       " 'Volcik': 454,\n",
       " 'Riedel': 455,\n",
       " 'Kremlacek': 456,\n",
       " 'Navratil': 457,\n",
       " 'Marek': 458,\n",
       " 'Vejvoda': 459,\n",
       " 'Skwor': 460,\n",
       " 'Linart': 461,\n",
       " 'Kreisinger': 462,\n",
       " 'Safko': 463,\n",
       " 'Kasimor': 464,\n",
       " 'Oesterreicher': 465,\n",
       " 'Blazek': 466,\n",
       " 'Sekovora': 467,\n",
       " 'Widerlechner': 468,\n",
       " 'Urista': 469,\n",
       " 'Hadash': 470,\n",
       " 'Coma': 471,\n",
       " 'Janosik': 472,\n",
       " 'Hanika': 473,\n",
       " 'Bolcar': 474,\n",
       " 'Konarik': 475,\n",
       " 'Demko': 476,\n",
       " 'Satorie': 477,\n",
       " 'Husk': 478,\n",
       " 'Novak': 479,\n",
       " 'Hafernik': 480,\n",
       " 'Hawlata': 481,\n",
       " 'Vaca': 482,\n",
       " 'Lynsmeier': 483,\n",
       " 'Peisar': 484,\n",
       " 'Kudrna': 485,\n",
       " 'Cerv': 486,\n",
       " 'Swatchak': 487,\n",
       " 'Grulich': 488,\n",
       " 'Skeril': 489,\n",
       " 'Macha': 490,\n",
       " 'Hladky': 491,\n",
       " 'Simonek': 492,\n",
       " 'Nemecek': 493,\n",
       " 'Veverka': 494,\n",
       " 'Loskot': 495,\n",
       " 'Neisser': 496,\n",
       " 'Clineburg': 497,\n",
       " 'Hanusch': 498,\n",
       " 'Blahut': 499,\n",
       " 'Petru': 500,\n",
       " 'Zitka': 501,\n",
       " 'Zipperer': 502,\n",
       " 'Zoucha': 503,\n",
       " 'Netsch': 504,\n",
       " 'Petersen': 505,\n",
       " 'Hana': 506,\n",
       " 'Stangl': 507,\n",
       " 'Ruzicka': 508,\n",
       " 'Cerney': 509,\n",
       " 'Hanek': 510,\n",
       " 'Borovka': 511,\n",
       " 'Opova': 512,\n",
       " 'Georgijev': 513,\n",
       " 'Kratschmar': 514,\n",
       " 'Biganska': 515,\n",
       " 'Bruckner': 516,\n",
       " 'Schenk': 517,\n",
       " 'Semick': 518,\n",
       " 'Novy': 519,\n",
       " 'Vavra': 520,\n",
       " 'Ocaskova': 521,\n",
       " 'Hrula': 522,\n",
       " 'Borowski': 523,\n",
       " 'Hynna': 524,\n",
       " 'Wizner': 525,\n",
       " 'Molcan': 526,\n",
       " 'Hlavsa': 527,\n",
       " 'Kulhanek': 528,\n",
       " 'Hodowal': 529,\n",
       " 'Nadvornizch': 530,\n",
       " 'Dvorak': 531,\n",
       " 'Adsit': 532,\n",
       " 'Janick': 533,\n",
       " 'Machacek': 534,\n",
       " 'Brabbery': 535,\n",
       " 'Kafka': 536,\n",
       " 'Koci': 537,\n",
       " 'Voneve': 538,\n",
       " 'Ballalatak': 539,\n",
       " 'Pretsch': 540,\n",
       " 'Benesch': 541,\n",
       " 'Schallom': 542,\n",
       " 'Kucharova': 543,\n",
       " 'Sokolik': 544,\n",
       " 'Koberna': 545,\n",
       " 'Malecha': 546,\n",
       " 'Sarna': 547,\n",
       " 'Schmeiser': 548,\n",
       " 'Uhlik': 549,\n",
       " 'Ondrisek': 550,\n",
       " 'Uerling': 551,\n",
       " 'Fillipova': 552,\n",
       " 'Sabol': 553,\n",
       " 'Faltejsek': 554,\n",
       " 'Tomes': 555,\n",
       " 'Michalovicova': 556,\n",
       " 'Chemlik': 557,\n",
       " 'Cihak': 558,\n",
       " 'Ajdrna': 559,\n",
       " 'Nestrojil': 560,\n",
       " 'Jares': 561,\n",
       " 'Schmied': 562,\n",
       " 'Pokorny': 563,\n",
       " 'Kocian': 564,\n",
       " 'Picha': 565,\n",
       " 'Camfrlova': 566,\n",
       " 'Kozumplikova': 567,\n",
       " 'Raffel': 568,\n",
       " 'Oborny': 569,\n",
       " 'Kriz': 570,\n",
       " 'Sztegon': 571,\n",
       " 'Morek': 572,\n",
       " 'Jonas': 573,\n",
       " 'Rafaj1': 574,\n",
       " 'Kasa': 575,\n",
       " 'Hanzlick': 576,\n",
       " 'Janutka': 577,\n",
       " 'Glatter': 578,\n",
       " 'Toman': 579,\n",
       " 'Tomasek': 580,\n",
       " 'Svocak': 581,\n",
       " 'Cernohous': 582,\n",
       " 'Fencl': 583,\n",
       " 'Malafa': 584,\n",
       " 'Duyava': 585,\n",
       " 'Hovanec': 586,\n",
       " 'Kremlicka': 587,\n",
       " 'Antonowitsch': 588,\n",
       " 'Matjeka': 589,\n",
       " 'Mayer': 590,\n",
       " 'Shima': 591,\n",
       " 'Mojjis': 592,\n",
       " 'Svotchak': 593,\n",
       " 'Paiser': 594,\n",
       " 'Tomanek': 595,\n",
       " 'Ruda': 596,\n",
       " 'Trnkova': 597,\n",
       " 'Kober': 598,\n",
       " 'Whitmire1': 599,\n",
       " 'Patril': 600,\n",
       " 'Kosko': 601,\n",
       " 'Kurtz': 602,\n",
       " 'Hrdy': 603,\n",
       " 'Bohunovsky': 604,\n",
       " 'Pesek': 605,\n",
       " 'Ozimuk': 606,\n",
       " 'Kaplanek': 607,\n",
       " 'Pachr': 608,\n",
       " 'Jarzembowski': 609,\n",
       " 'Brousil': 610,\n",
       " 'Fojtikova': 611,\n",
       " 'Morava': 612,\n",
       " 'Hrabak': 613,\n",
       " 'Chromy': 614,\n",
       " 'Drassal': 615,\n",
       " 'Stegon': 616,\n",
       " 'Quasninsky': 617,\n",
       " 'Kenzel': 618,\n",
       " 'Siegl': 619,\n",
       " 'Monfort': 620,\n",
       " 'Stepan': 621,\n",
       " 'Wiesner': 622,\n",
       " 'Vlasak': 623,\n",
       " 'Schlantz': 624,\n",
       " 'Jirava': 625,\n",
       " 'Stramba': 626,\n",
       " 'Kuffel': 627,\n",
       " 'Blecha': 628,\n",
       " 'Rozinek': 629,\n",
       " 'Koukal': 630,\n",
       " 'Cablikova': 631,\n",
       " 'Silhan': 632,\n",
       " 'Kara': 633,\n",
       " 'Svejda': 634,\n",
       " 'Dopita': 635,\n",
       " 'Wykruta': 636,\n",
       " 'Planick': 637,\n",
       " 'Piller': 638,\n",
       " 'Mojzis': 639,\n",
       " 'Ransom': 640,\n",
       " 'Soucek': 641,\n",
       " 'Lawa': 642,\n",
       " 'Klein': 643,\n",
       " 'Subertova': 644,\n",
       " 'Jirik': 645,\n",
       " 'Kanak': 646,\n",
       " 'Lind': 647,\n",
       " 'Giersig': 648,\n",
       " 'Slezak': 649,\n",
       " 'Palzewicz': 650,\n",
       " 'Tikal': 651,\n",
       " 'Slepica': 652,\n",
       " 'Krawiec': 653,\n",
       " 'Chermak': 654,\n",
       " 'Bilek': 655,\n",
       " 'Jobst': 656,\n",
       " 'Frierdich': 657,\n",
       " 'Korycan': 658,\n",
       " 'Brezovjak': 659,\n",
       " 'Kofel': 660,\n",
       " 'Maly': 661,\n",
       " 'Marik': 662,\n",
       " 'Spoerl': 663,\n",
       " 'Prachar': 664,\n",
       " 'Gavalok': 665,\n",
       " 'Spicka': 666,\n",
       " 'Persein': 667,\n",
       " 'Koza': 668,\n",
       " 'Nadwornik': 669,\n",
       " 'Hradek': 670,\n",
       " 'Suchanka': 671,\n",
       " 'Betlach': 672,\n",
       " 'Perevuznik': 673,\n",
       " 'Tykal': 674,\n",
       " 'Soukup': 675,\n",
       " 'Divoky': 676,\n",
       " 'Vlasek': 677,\n",
       " 'Smith': 678,\n",
       " 'Rebka': 679,\n",
       " 'Kofron': 680,\n",
       " 'Urbanovska': 681,\n",
       " 'Weiss': 682,\n",
       " 'Hodoval': 683,\n",
       " 'Kusak': 684,\n",
       " 'Perina': 685,\n",
       " 'Vykruta': 686,\n",
       " 'Rzehak': 687,\n",
       " 'Panek': 688,\n",
       " 'Jirovy': 689,\n",
       " 'Kreutschmer': 690,\n",
       " 'Ritchie': 691,\n",
       " 'Wood': 692,\n",
       " 'Kopecky': 693,\n",
       " 'Opp': 694,\n",
       " 'Merta': 695,\n",
       " 'Petrezelka': 696,\n",
       " 'Schubert': 697,\n",
       " 'Maxa/B': 698,\n",
       " 'Werlla': 699,\n",
       " 'Treblik': 700,\n",
       " 'StrakaO': 701,\n",
       " 'Urbanek': 702,\n",
       " 'Navara': 703,\n",
       " 'Pech': 704,\n",
       " 'Ustohal': 705,\n",
       " 'Jelinek': 706,\n",
       " 'Pear': 707,\n",
       " 'Buchta': 708,\n",
       " 'Malec': 709,\n",
       " 'Hudecek': 710,\n",
       " 'Driml': 711,\n",
       " 'Svoboda': 712,\n",
       " 'Karlovsky': 713,\n",
       " 'Borovsky': 714,\n",
       " 'Stites': 715,\n",
       " 'Pavlik': 716,\n",
       " 'Daal': 717,\n",
       " 'Houtum': 718,\n",
       " 'Apeldoorn': 719,\n",
       " 'Laar': 720,\n",
       " 'Vennen': 721,\n",
       " 'Simonis': 722,\n",
       " 'Rompaye': 723,\n",
       " 'Snyder': 724,\n",
       " 'Specht': 725,\n",
       " 'Houte': 726,\n",
       " 'Smets': 727,\n",
       " 'Seeger': 728,\n",
       " 'Rademakers': 729,\n",
       " 'Rijnder': 730,\n",
       " 'Roijakker': 731,\n",
       " 'Penners': 732,\n",
       " 'Kranz': 733,\n",
       " 'Akkeren': 734,\n",
       " 'Koeman': 735,\n",
       " 'Haanraats': 736,\n",
       " 'Aalsburg': 737,\n",
       " 'Lucas': 738,\n",
       " 'Rooiakkers': 739,\n",
       " 'Haanrade': 740,\n",
       " 'Snyders': 741,\n",
       " 'Lyon': 742,\n",
       " 'Aalst': 743,\n",
       " 'Klerkx': 744,\n",
       " 'Nifterik': 745,\n",
       " 'Peij': 746,\n",
       " 'Ramecker': 747,\n",
       " 'Schoorel': 748,\n",
       " 'Houttum': 749,\n",
       " 'Kanne': 750,\n",
       " 'Daele': 751,\n",
       " 'Sneijders': 752,\n",
       " 'Kolen': 753,\n",
       " 'Tunneson': 754,\n",
       " 'Mulder': 755,\n",
       " 'Klerkse': 756,\n",
       " 'Meeuwessen': 757,\n",
       " 'Dale': 758,\n",
       " 'Veen': 759,\n",
       " 'Schoonraad': 760,\n",
       " 'Seghers': 761,\n",
       " 'Amstel': 762,\n",
       " 'Klerken': 763,\n",
       " 'Achthoven': 764,\n",
       " 'Ramaker': 765,\n",
       " 'Penner': 766,\n",
       " 'Theunissen': 767,\n",
       " 'Bueren': 768,\n",
       " 'Assen': 769,\n",
       " 'Hanraets': 770,\n",
       " 'Reynder': 771,\n",
       " 'Buren': 772,\n",
       " 'Dael': 773,\n",
       " 'Laren': 774,\n",
       " 'Pey': 775,\n",
       " 'Cann': 776,\n",
       " 'Silje': 777,\n",
       " 'Sneijder': 778,\n",
       " 'Nifterick': 779,\n",
       " 'Hautem': 780,\n",
       " 'Leeuwenhoek': 781,\n",
       " 'Agteren': 782,\n",
       " 'Penders': 783,\n",
       " 'Sevriens': 784,\n",
       " 'Offermans': 785,\n",
       " 'Denend': 786,\n",
       " 'Reinders': 787,\n",
       " 'Berg': 788,\n",
       " 'Lauwens': 789,\n",
       " 'Merckx': 790,\n",
       " 'Sneijer': 791,\n",
       " 'Klerx': 792,\n",
       " 'Roijakkers': 793,\n",
       " 'Rompuy': 794,\n",
       " 'Schuyler': 795,\n",
       " 'Michel': 796,\n",
       " 'Roggeveen': 797,\n",
       " 'Antwerp': 798,\n",
       " 'Romijn': 799,\n",
       " 'Rooijakkers': 800,\n",
       " 'Donk': 801,\n",
       " 'Can': 802,\n",
       " 'Kuipers': 803,\n",
       " 'Schoonenburg': 804,\n",
       " 'Ogterop': 805,\n",
       " 'Reinder': 806,\n",
       " 'Peerenboom': 807,\n",
       " 'Adrichem': 808,\n",
       " 'Smit': 809,\n",
       " 'Reijnder': 810,\n",
       " 'Vandroogenbroeck': 811,\n",
       " 'Romeijn': 812,\n",
       " 'Vann': 813,\n",
       " 'Schenck': 814,\n",
       " 'Niftrik': 815,\n",
       " 'Avest': 816,\n",
       " 'Mohren': 817,\n",
       " 'Rompaey': 818,\n",
       " 'Pender': 819,\n",
       " 'Meisner': 820,\n",
       " 'Smits': 821,\n",
       " 'Haenraets': 822,\n",
       " 'Seegers': 823,\n",
       " 'Hassel': 824,\n",
       " 'Sniders': 825,\n",
       " 'Schrijnemakers': 826,\n",
       " 'Mas': 827,\n",
       " 'Lauwers': 828,\n",
       " 'Haanraads': 829,\n",
       " 'Mooren': 830,\n",
       " 'Schneiders': 831,\n",
       " 'Sneiders': 832,\n",
       " 'Snell': 833,\n",
       " 'Simon': 834,\n",
       " 'Nagel': 835,\n",
       " 'Kloeter': 836,\n",
       " 'Kappel': 837,\n",
       " 'Middlesworth': 838,\n",
       " 'Asch': 839,\n",
       " 'Amersvoort': 840,\n",
       " 'Schorel': 841,\n",
       " 'Kuijpers': 842,\n",
       " 'Stoep': 843,\n",
       " 'Achteren': 844,\n",
       " 'Krantz': 845,\n",
       " 'Rossem': 846,\n",
       " 'Schneijder': 847,\n",
       " 'Paulissen': 848,\n",
       " 'Tholberg': 849,\n",
       " 'Rietveld': 850,\n",
       " 'Herten': 851,\n",
       " 'Peter': 852,\n",
       " 'Ophoven': 853,\n",
       " 'Rompaeij': 854,\n",
       " 'Aller': 855,\n",
       " 'Roosa': 856,\n",
       " 'Philips': 857,\n",
       " 'Hout': 858,\n",
       " 'Meeuwissen': 859,\n",
       " 'Severins': 860,\n",
       " 'Romijnders': 861,\n",
       " 'Kuiper': 862,\n",
       " 'Rooiakker': 863,\n",
       " 'Ryskamp': 864,\n",
       " 'Altena': 865,\n",
       " 'Ramaaker': 866,\n",
       " 'Ter': 867,\n",
       " 'Aggelen': 868,\n",
       " 'Rijnders': 869,\n",
       " 'Raske': 870,\n",
       " 'Rompa': 871,\n",
       " 'Andel': 872,\n",
       " 'Tillens': 873,\n",
       " 'Schneijders': 874,\n",
       " 'Marqueringh': 875,\n",
       " 'Rompaij': 876,\n",
       " 'Hautum': 877,\n",
       " 'Slootmaekers': 878,\n",
       " 'Kools': 879,\n",
       " 'Kloet': 880,\n",
       " 'Antwerpen': 881,\n",
       " 'Spiker': 882,\n",
       " 'Meeuwes': 883,\n",
       " 'Haanrath': 884,\n",
       " 'Severijns': 885,\n",
       " 'Schwarzenberg': 886,\n",
       " 'Kool': 887,\n",
       " 'Meeuweszen': 888,\n",
       " 'Snijder': 889,\n",
       " 'Althuis': 890,\n",
       " 'Peeters': 891,\n",
       " 'Houtem': 892,\n",
       " 'Seelen': 893,\n",
       " 'Snaaijer': 894,\n",
       " 'Canne': 895,\n",
       " 'Rutten': 896,\n",
       " 'Langbroek': 897,\n",
       " 'Horn': 898,\n",
       " 'Kollen': 899,\n",
       " 'Maes': 900,\n",
       " 'Baarle': 901,\n",
       " 'Schoorl': 902,\n",
       " 'Sanna': 903,\n",
       " 'Roosevelt': 904,\n",
       " 'Koumans': 905,\n",
       " 'Akker': 906,\n",
       " 'Koemans': 907,\n",
       " 'Richard': 908,\n",
       " 'Nelissen': 909,\n",
       " 'Rooijakker': 910,\n",
       " 'Reynders': 911,\n",
       " 'Spijker': 912,\n",
       " 'Middelburg': 913,\n",
       " 'Prinsen': 914,\n",
       " 'Vandale': 915,\n",
       " 'Kloeten': 916,\n",
       " 'Beek': 917,\n",
       " 'Snider': 918,\n",
       " 'Rompu': 919,\n",
       " 'Buggenum': 920,\n",
       " 'Kikkert': 921,\n",
       " 'Rossum': 922,\n",
       " 'Oorschot': 923,\n",
       " 'Daalen': 924,\n",
       " 'Venn': 925,\n",
       " 'Ramakers': 926,\n",
       " 'Rameckers': 927,\n",
       " 'Rumpade': 928,\n",
       " 'Ven': 929,\n",
       " 'Segers': 930,\n",
       " 'Klerks': 931,\n",
       " 'Maas': 932,\n",
       " 'Andringa': 933,\n",
       " 'Tunison': 934,\n",
       " 'Meeuwsen': 935,\n",
       " 'Muyskens': 936,\n",
       " 'Teunissen': 937,\n",
       " 'Leeuwenhoeck': 938,\n",
       " 'Aart': 939,\n",
       " 'Marquering': 940,\n",
       " 'Haenraats': 941,\n",
       " 'Vane': 942,\n",
       " 'Harker': 943,\n",
       " 'Croucher': 944,\n",
       " 'Roscoe': 945,\n",
       " 'Jenkin': 946,\n",
       " 'Sinha': 947,\n",
       " 'Hind': 948,\n",
       " 'Ewing': 949,\n",
       " 'Stout': 950,\n",
       " 'Keefe': 951,\n",
       " 'Lynes': 952,\n",
       " 'Plummer': 953,\n",
       " 'Seymour': 954,\n",
       " 'Hodder': 955,\n",
       " 'Grady': 956,\n",
       " 'Dawkins': 957,\n",
       " 'Whitmore': 958,\n",
       " 'Evans': 959,\n",
       " 'Mccall': 960,\n",
       " 'Peach': 961,\n",
       " 'Legg': 962,\n",
       " 'Keith': 963,\n",
       " 'Fowley': 964,\n",
       " 'Leyshon': 965,\n",
       " 'Caldwell': 966,\n",
       " 'Abraham': 967,\n",
       " 'Ashbridge': 968,\n",
       " 'Morgan': 969,\n",
       " 'Thurling': 970,\n",
       " 'Errity': 971,\n",
       " 'Mcavoy': 972,\n",
       " 'Turney': 973,\n",
       " 'Elphick': 974,\n",
       " 'Osmond': 975,\n",
       " 'Nurse': 976,\n",
       " 'Wears': 977,\n",
       " 'Fleming': 978,\n",
       " 'Santos': 979,\n",
       " 'Bush': 980,\n",
       " 'Fulker': 981,\n",
       " 'Prior': 982,\n",
       " 'Dumont': 983,\n",
       " 'Gulley': 984,\n",
       " 'Glossop': 985,\n",
       " 'Plumb': 986,\n",
       " 'Redman': 987,\n",
       " 'Wilson': 988,\n",
       " 'Hancock': 989,\n",
       " 'Willetts': 990,\n",
       " 'Oldham': 991,\n",
       " 'Owings': 992,\n",
       " 'Talbot': 993,\n",
       " 'Arrowsmith': 994,\n",
       " 'Kidner': 995,\n",
       " 'Smallwood': 996,\n",
       " 'Mather': 997,\n",
       " 'Browne': 998,\n",
       " 'Adlam': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_vocab.token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4659251",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<UNK>',\n",
       " 1: 'Totah',\n",
       " 2: 'Abboud',\n",
       " 3: 'Fakhoury',\n",
       " 4: 'Srour',\n",
       " 5: 'Sayegh',\n",
       " 6: 'Cham',\n",
       " 7: 'Haik',\n",
       " 8: 'Kattan',\n",
       " 9: 'Khouri',\n",
       " 10: 'Antoun',\n",
       " 11: 'Wasem',\n",
       " 12: 'Seif',\n",
       " 13: 'Guirguis',\n",
       " 14: 'Sarkis',\n",
       " 15: 'Said',\n",
       " 16: 'Malouf',\n",
       " 17: 'Bishara',\n",
       " 18: 'Ganim',\n",
       " 19: 'Baz',\n",
       " 20: 'Assaf',\n",
       " 21: 'Nader',\n",
       " 22: 'Isa',\n",
       " 23: 'Awad',\n",
       " 24: 'Deeb',\n",
       " 25: 'Kanaan',\n",
       " 26: 'Quraishi',\n",
       " 27: 'Atiyeh',\n",
       " 28: 'Boutros',\n",
       " 29: 'Sabbagh',\n",
       " 30: 'Mustafa',\n",
       " 31: 'Mansour',\n",
       " 32: 'Hadad',\n",
       " 33: 'Salib',\n",
       " 34: 'Sabbag',\n",
       " 35: 'Kassab',\n",
       " 36: 'Moghadam',\n",
       " 37: 'Najjar',\n",
       " 38: 'Gerges',\n",
       " 39: 'Safar',\n",
       " 40: 'Mifsud',\n",
       " 41: 'Shalhoub',\n",
       " 42: 'Koury',\n",
       " 43: 'Kalb',\n",
       " 44: 'Harb',\n",
       " 45: 'Toma',\n",
       " 46: 'Maalouf',\n",
       " 47: 'Kouri',\n",
       " 48: 'Shadid',\n",
       " 49: 'Dagher',\n",
       " 50: 'Tahan',\n",
       " 51: 'Bahar',\n",
       " 52: 'Boulos',\n",
       " 53: 'Attia',\n",
       " 54: 'Amari',\n",
       " 55: 'Naser',\n",
       " 56: 'Bazzi',\n",
       " 57: 'Bata',\n",
       " 58: 'Shamoon',\n",
       " 59: 'Hanania',\n",
       " 60: 'Masih',\n",
       " 61: 'Halabi',\n",
       " 62: 'Saliba',\n",
       " 63: 'Antar',\n",
       " 64: 'Qureshi',\n",
       " 65: 'Kassis',\n",
       " 66: 'Sarraf',\n",
       " 67: 'Essa',\n",
       " 68: 'Touma',\n",
       " 69: 'Maroun',\n",
       " 70: 'Almasi',\n",
       " 71: 'Ganem',\n",
       " 72: 'Bitar',\n",
       " 73: 'Khoury',\n",
       " 74: 'Aswad',\n",
       " 75: 'Sleiman',\n",
       " 76: 'Handal',\n",
       " 77: 'Abadi',\n",
       " 78: 'Naifeh',\n",
       " 79: 'Shammas',\n",
       " 80: 'Tuma',\n",
       " 81: 'Shamon',\n",
       " 82: 'Botros',\n",
       " 83: 'Basara',\n",
       " 84: 'Hajjar',\n",
       " 85: 'Mikhail',\n",
       " 86: 'Rahal',\n",
       " 87: 'Ghanem',\n",
       " 88: 'Baba',\n",
       " 89: 'Haddad',\n",
       " 90: 'Hakimi',\n",
       " 91: 'Asghar',\n",
       " 92: 'Maloof',\n",
       " 93: 'Nazari',\n",
       " 94: 'Gaber',\n",
       " 95: 'Zogby',\n",
       " 96: 'Arian',\n",
       " 97: 'Morcos',\n",
       " 98: 'Nassar',\n",
       " 99: 'Tannous',\n",
       " 100: 'Ghannam',\n",
       " 101: 'Ba',\n",
       " 102: 'Asker',\n",
       " 103: 'Daher',\n",
       " 104: 'Shamoun',\n",
       " 105: 'Nahas',\n",
       " 106: 'Issa',\n",
       " 107: 'Samaha',\n",
       " 108: 'Asfour',\n",
       " 109: 'Hor',\n",
       " 110: 'Fung',\n",
       " 111: 'Mui',\n",
       " 112: 'Kong',\n",
       " 113: 'Nao',\n",
       " 114: 'Ruan',\n",
       " 115: 'Bai',\n",
       " 116: 'Zhao',\n",
       " 117: 'Yee',\n",
       " 118: 'Yau',\n",
       " 119: 'Woo',\n",
       " 120: 'Min',\n",
       " 121: 'Wan',\n",
       " 122: 'Qiao',\n",
       " 123: 'Zong',\n",
       " 124: 'Sui',\n",
       " 125: 'Zhu',\n",
       " 126: 'Joe',\n",
       " 127: 'Chieu',\n",
       " 128: 'Che',\n",
       " 129: 'Won',\n",
       " 130: 'Tsang',\n",
       " 131: 'Wei',\n",
       " 132: 'Shu',\n",
       " 133: 'Eng',\n",
       " 134: 'Lau',\n",
       " 135: 'Jiang',\n",
       " 136: 'Zeng',\n",
       " 137: 'Jia',\n",
       " 138: 'Dong',\n",
       " 139: 'Zhang',\n",
       " 140: 'Tao',\n",
       " 141: 'Guan',\n",
       " 142: 'Niu',\n",
       " 143: 'Nie',\n",
       " 144: 'Ou-Yang',\n",
       " 145: 'Loh',\n",
       " 146: 'Huan',\n",
       " 147: 'Bing',\n",
       " 148: 'Chew',\n",
       " 149: 'Khu',\n",
       " 150: 'Feng',\n",
       " 151: 'Shang',\n",
       " 152: 'Cheng',\n",
       " 153: 'Hua',\n",
       " 154: 'Bian',\n",
       " 155: 'Luo',\n",
       " 156: 'Chan',\n",
       " 157: 'Ban',\n",
       " 158: 'Lai',\n",
       " 159: 'Pang',\n",
       " 160: 'Au-Yong',\n",
       " 161: 'Ran',\n",
       " 162: 'Siew',\n",
       " 163: 'Dai',\n",
       " 164: 'Long',\n",
       " 165: 'Yun',\n",
       " 166: 'Chong',\n",
       " 167: 'Fei',\n",
       " 168: 'Tong',\n",
       " 169: 'Hao',\n",
       " 170: 'She',\n",
       " 171: 'Shen',\n",
       " 172: 'Shui',\n",
       " 173: 'Yue',\n",
       " 174: 'You',\n",
       " 175: 'Chu',\n",
       " 176: 'Xing',\n",
       " 177: 'Tai',\n",
       " 178: 'Chang',\n",
       " 179: 'Thean',\n",
       " 180: 'Rao',\n",
       " 181: 'Pian',\n",
       " 182: 'Kwong',\n",
       " 183: 'Zhou',\n",
       " 184: 'Hew',\n",
       " 185: 'Wang',\n",
       " 186: 'Thien',\n",
       " 187: 'Seah',\n",
       " 188: 'Jiao',\n",
       " 189: 'Tse',\n",
       " 190: 'Ang',\n",
       " 191: 'Zhi',\n",
       " 192: 'Lam',\n",
       " 193: 'Ying',\n",
       " 194: 'Cen',\n",
       " 195: 'Tso',\n",
       " 196: 'Ming',\n",
       " 197: 'Bei',\n",
       " 198: 'Kan',\n",
       " 199: 'Yep',\n",
       " 200: 'Ow-Yang',\n",
       " 201: 'Huang',\n",
       " 202: 'Mei',\n",
       " 203: 'Xian',\n",
       " 204: 'Deng',\n",
       " 205: 'Yap',\n",
       " 206: 'Guang',\n",
       " 207: 'Mah',\n",
       " 208: 'Tow',\n",
       " 209: 'Shan',\n",
       " 210: 'Qin',\n",
       " 211: 'Chen',\n",
       " 212: 'Lew',\n",
       " 213: 'Juan',\n",
       " 214: 'Fan',\n",
       " 215: 'Gauk',\n",
       " 216: 'Pan',\n",
       " 217: 'Jian',\n",
       " 218: 'Law',\n",
       " 219: 'Zou',\n",
       " 220: 'Gong',\n",
       " 221: 'Song',\n",
       " 222: 'See',\n",
       " 223: 'Ping',\n",
       " 224: 'Liang',\n",
       " 225: 'Jue',\n",
       " 226: 'Kwan',\n",
       " 227: 'Foong',\n",
       " 228: 'Kwei',\n",
       " 229: 'Zhai',\n",
       " 230: 'Xie',\n",
       " 231: 'Qiu',\n",
       " 232: 'Xiang',\n",
       " 233: 'Lu:',\n",
       " 234: 'Huie',\n",
       " 235: 'Kui',\n",
       " 236: 'Zha',\n",
       " 237: 'Xin',\n",
       " 238: 'Quan',\n",
       " 239: 'Ding',\n",
       " 240: 'Qian',\n",
       " 241: 'Yin',\n",
       " 242: 'Que',\n",
       " 243: 'Xun',\n",
       " 244: 'Lang',\n",
       " 245: 'Duan',\n",
       " 246: 'Seow',\n",
       " 247: 'Siu',\n",
       " 248: 'Yuan',\n",
       " 249: 'Shuo',\n",
       " 250: 'Kang',\n",
       " 251: 'Huo',\n",
       " 252: 'Zang',\n",
       " 253: 'Jiu',\n",
       " 254: 'Zhan',\n",
       " 255: 'Man',\n",
       " 256: 'Yang',\n",
       " 257: 'Shao',\n",
       " 258: 'Cui',\n",
       " 259: 'Khoo',\n",
       " 260: 'Xiao',\n",
       " 261: 'Cai',\n",
       " 262: 'Tsen',\n",
       " 263: 'Lian',\n",
       " 264: 'Gou',\n",
       " 265: 'Wong',\n",
       " 266: 'Hui',\n",
       " 267: 'Tang',\n",
       " 268: 'Gwock',\n",
       " 269: 'Miao',\n",
       " 270: 'Shaw',\n",
       " 271: 'Liu',\n",
       " 272: 'Sum',\n",
       " 273: 'Cheung',\n",
       " 274: 'Sze',\n",
       " 275: 'Zhui',\n",
       " 276: 'Cong',\n",
       " 277: 'Kau',\n",
       " 278: 'Zhen',\n",
       " 279: 'Jing',\n",
       " 280: 'Rang',\n",
       " 281: 'Mao',\n",
       " 282: 'Shuai',\n",
       " 283: 'Cuan',\n",
       " 284: 'Rong',\n",
       " 285: 'Shi',\n",
       " 286: 'Zhong',\n",
       " 287: 'Zhuo',\n",
       " 288: 'Chi',\n",
       " 289: 'Yan',\n",
       " 290: 'Han',\n",
       " 291: 'Gai',\n",
       " 292: 'Bao',\n",
       " 293: 'Xue',\n",
       " 294: 'Jin',\n",
       " 295: 'Cao',\n",
       " 296: 'Lim',\n",
       " 297: 'Tze',\n",
       " 298: 'Mar',\n",
       " 299: 'Yao',\n",
       " 300: 'Wen',\n",
       " 301: 'Gim',\n",
       " 302: 'Zhuan',\n",
       " 303: 'Ling',\n",
       " 304: 'Lin',\n",
       " 305: 'Teng',\n",
       " 306: 'Rui',\n",
       " 307: 'Dan',\n",
       " 308: 'Bui',\n",
       " 309: 'Guo',\n",
       " 310: 'Gan',\n",
       " 311: 'Hang',\n",
       " 312: 'Chai',\n",
       " 313: 'Kuang',\n",
       " 314: 'Jedlicka',\n",
       " 315: 'Koliha',\n",
       " 316: 'Khork',\n",
       " 317: 'Kucera',\n",
       " 318: 'Schneider',\n",
       " 319: 'Dolezal',\n",
       " 320: 'Rumisek',\n",
       " 321: 'Heidl',\n",
       " 322: 'Gabrisova',\n",
       " 323: 'Cermak',\n",
       " 324: 'Kazimor',\n",
       " 325: 'Nowak',\n",
       " 326: 'Alt',\n",
       " 327: 'Bock',\n",
       " 328: 'Urbanek1',\n",
       " 329: 'Prehatney',\n",
       " 330: 'Stotzky',\n",
       " 331: 'Ballaltick',\n",
       " 332: 'Skala',\n",
       " 333: 'Zak',\n",
       " 334: 'Janca',\n",
       " 335: 'Hajkova',\n",
       " 336: 'Herodes',\n",
       " 337: 'Hiorvst',\n",
       " 338: 'Matejka',\n",
       " 339: 'Prill',\n",
       " 340: 'Charlott',\n",
       " 341: 'Sappe',\n",
       " 342: 'Finferovy',\n",
       " 343: 'Riha',\n",
       " 344: 'Chicken',\n",
       " 345: 'Svotak',\n",
       " 346: 'Bartonova',\n",
       " 347: 'Kolacny',\n",
       " 348: 'Cerny',\n",
       " 349: 'Korycansky',\n",
       " 350: 'Vlach',\n",
       " 351: 'Borovski',\n",
       " 352: 'Snelker',\n",
       " 353: 'Paisar',\n",
       " 354: 'Till',\n",
       " 355: 'Cerda',\n",
       " 356: 'Kessel',\n",
       " 357: 'Psik',\n",
       " 358: 'Geryk',\n",
       " 359: 'Kesl',\n",
       " 360: 'MonkoAustria',\n",
       " 361: 'Okenfuss',\n",
       " 362: 'Furtsch',\n",
       " 363: 'Srda',\n",
       " 364: 'Antonowitz',\n",
       " 365: 'Havlatova',\n",
       " 366: 'Hanzlik',\n",
       " 367: 'Homulka',\n",
       " 368: 'Pitterman',\n",
       " 369: 'Holan',\n",
       " 370: 'Skokan',\n",
       " 371: 'Ponec',\n",
       " 372: 'Seger',\n",
       " 373: 'Dinko',\n",
       " 374: 'Trampota',\n",
       " 375: 'Fenyo',\n",
       " 376: 'Pfeifer',\n",
       " 377: 'Krupala',\n",
       " 378: 'Pawlak',\n",
       " 379: 'Janoch',\n",
       " 380: 'Jirku',\n",
       " 381: 'Markytan',\n",
       " 382: 'Stupka',\n",
       " 383: 'Klimes',\n",
       " 384: 'Havlice',\n",
       " 385: 'Cvacek',\n",
       " 386: 'Glockl',\n",
       " 387: 'Jaluvka',\n",
       " 388: 'Sponer',\n",
       " 389: 'Hartl',\n",
       " 390: 'Muhlbauer',\n",
       " 391: 'Mozzis',\n",
       " 392: 'Hajicek',\n",
       " 393: 'Peary',\n",
       " 394: 'Tejc',\n",
       " 395: 'Grabski',\n",
       " 396: 'Grygarova',\n",
       " 397: 'Staska',\n",
       " 398: 'Kruessel',\n",
       " 399: 'Pinter',\n",
       " 400: 'Vaculova',\n",
       " 401: 'Zaruba',\n",
       " 402: 'Geier',\n",
       " 403: 'Abl',\n",
       " 404: 'Cernochova',\n",
       " 405: 'Faltysek',\n",
       " 406: 'Colling',\n",
       " 407: 'Mudra',\n",
       " 408: 'Savchak',\n",
       " 409: 'Krhovsky',\n",
       " 410: 'Opizka',\n",
       " 411: 'Navrkal',\n",
       " 412: 'Pavlicka',\n",
       " 413: 'Skomicka',\n",
       " 414: 'Demall',\n",
       " 415: 'Slejtr',\n",
       " 416: 'Nemec',\n",
       " 417: 'Trampotova',\n",
       " 418: 'Zwolenksy',\n",
       " 419: 'Hajek',\n",
       " 420: 'Chalupka',\n",
       " 421: 'Ludwig',\n",
       " 422: 'Janicek',\n",
       " 423: 'Entler',\n",
       " 424: 'Pillar',\n",
       " 425: 'Krivan',\n",
       " 426: 'Pavlu',\n",
       " 427: 'Egr',\n",
       " 428: 'Koma',\n",
       " 429: 'Purdes',\n",
       " 430: 'Kupfel',\n",
       " 431: 'Dehmel',\n",
       " 432: 'Weineltk',\n",
       " 433: 'Slivka',\n",
       " 434: 'Votke',\n",
       " 435: 'Katschker',\n",
       " 436: 'Finfera',\n",
       " 437: 'Rezac',\n",
       " 438: 'Jindra',\n",
       " 439: 'Kouba',\n",
       " 440: 'Zajicek',\n",
       " 441: 'Holub',\n",
       " 442: 'Pellar',\n",
       " 443: 'Dempko',\n",
       " 444: 'Krivolavy',\n",
       " 445: 'Neusser',\n",
       " 446: 'Samz',\n",
       " 447: 'Bacon',\n",
       " 448: 'Wilchek',\n",
       " 449: 'Bohac',\n",
       " 450: 'Plisko',\n",
       " 451: 'Victor',\n",
       " 452: 'Sip',\n",
       " 453: 'Klemper',\n",
       " 454: 'Volcik',\n",
       " 455: 'Riedel',\n",
       " 456: 'Kremlacek',\n",
       " 457: 'Navratil',\n",
       " 458: 'Marek',\n",
       " 459: 'Vejvoda',\n",
       " 460: 'Skwor',\n",
       " 461: 'Linart',\n",
       " 462: 'Kreisinger',\n",
       " 463: 'Safko',\n",
       " 464: 'Kasimor',\n",
       " 465: 'Oesterreicher',\n",
       " 466: 'Blazek',\n",
       " 467: 'Sekovora',\n",
       " 468: 'Widerlechner',\n",
       " 469: 'Urista',\n",
       " 470: 'Hadash',\n",
       " 471: 'Coma',\n",
       " 472: 'Janosik',\n",
       " 473: 'Hanika',\n",
       " 474: 'Bolcar',\n",
       " 475: 'Konarik',\n",
       " 476: 'Demko',\n",
       " 477: 'Satorie',\n",
       " 478: 'Husk',\n",
       " 479: 'Novak',\n",
       " 480: 'Hafernik',\n",
       " 481: 'Hawlata',\n",
       " 482: 'Vaca',\n",
       " 483: 'Lynsmeier',\n",
       " 484: 'Peisar',\n",
       " 485: 'Kudrna',\n",
       " 486: 'Cerv',\n",
       " 487: 'Swatchak',\n",
       " 488: 'Grulich',\n",
       " 489: 'Skeril',\n",
       " 490: 'Macha',\n",
       " 491: 'Hladky',\n",
       " 492: 'Simonek',\n",
       " 493: 'Nemecek',\n",
       " 494: 'Veverka',\n",
       " 495: 'Loskot',\n",
       " 496: 'Neisser',\n",
       " 497: 'Clineburg',\n",
       " 498: 'Hanusch',\n",
       " 499: 'Blahut',\n",
       " 500: 'Petru',\n",
       " 501: 'Zitka',\n",
       " 502: 'Zipperer',\n",
       " 503: 'Zoucha',\n",
       " 504: 'Netsch',\n",
       " 505: 'Petersen',\n",
       " 506: 'Hana',\n",
       " 507: 'Stangl',\n",
       " 508: 'Ruzicka',\n",
       " 509: 'Cerney',\n",
       " 510: 'Hanek',\n",
       " 511: 'Borovka',\n",
       " 512: 'Opova',\n",
       " 513: 'Georgijev',\n",
       " 514: 'Kratschmar',\n",
       " 515: 'Biganska',\n",
       " 516: 'Bruckner',\n",
       " 517: 'Schenk',\n",
       " 518: 'Semick',\n",
       " 519: 'Novy',\n",
       " 520: 'Vavra',\n",
       " 521: 'Ocaskova',\n",
       " 522: 'Hrula',\n",
       " 523: 'Borowski',\n",
       " 524: 'Hynna',\n",
       " 525: 'Wizner',\n",
       " 526: 'Molcan',\n",
       " 527: 'Hlavsa',\n",
       " 528: 'Kulhanek',\n",
       " 529: 'Hodowal',\n",
       " 530: 'Nadvornizch',\n",
       " 531: 'Dvorak',\n",
       " 532: 'Adsit',\n",
       " 533: 'Janick',\n",
       " 534: 'Machacek',\n",
       " 535: 'Brabbery',\n",
       " 536: 'Kafka',\n",
       " 537: 'Koci',\n",
       " 538: 'Voneve',\n",
       " 539: 'Ballalatak',\n",
       " 540: 'Pretsch',\n",
       " 541: 'Benesch',\n",
       " 542: 'Schallom',\n",
       " 543: 'Kucharova',\n",
       " 544: 'Sokolik',\n",
       " 545: 'Koberna',\n",
       " 546: 'Malecha',\n",
       " 547: 'Sarna',\n",
       " 548: 'Schmeiser',\n",
       " 549: 'Uhlik',\n",
       " 550: 'Ondrisek',\n",
       " 551: 'Uerling',\n",
       " 552: 'Fillipova',\n",
       " 553: 'Sabol',\n",
       " 554: 'Faltejsek',\n",
       " 555: 'Tomes',\n",
       " 556: 'Michalovicova',\n",
       " 557: 'Chemlik',\n",
       " 558: 'Cihak',\n",
       " 559: 'Ajdrna',\n",
       " 560: 'Nestrojil',\n",
       " 561: 'Jares',\n",
       " 562: 'Schmied',\n",
       " 563: 'Pokorny',\n",
       " 564: 'Kocian',\n",
       " 565: 'Picha',\n",
       " 566: 'Camfrlova',\n",
       " 567: 'Kozumplikova',\n",
       " 568: 'Raffel',\n",
       " 569: 'Oborny',\n",
       " 570: 'Kriz',\n",
       " 571: 'Sztegon',\n",
       " 572: 'Morek',\n",
       " 573: 'Jonas',\n",
       " 574: 'Rafaj1',\n",
       " 575: 'Kasa',\n",
       " 576: 'Hanzlick',\n",
       " 577: 'Janutka',\n",
       " 578: 'Glatter',\n",
       " 579: 'Toman',\n",
       " 580: 'Tomasek',\n",
       " 581: 'Svocak',\n",
       " 582: 'Cernohous',\n",
       " 583: 'Fencl',\n",
       " 584: 'Malafa',\n",
       " 585: 'Duyava',\n",
       " 586: 'Hovanec',\n",
       " 587: 'Kremlicka',\n",
       " 588: 'Antonowitsch',\n",
       " 589: 'Matjeka',\n",
       " 590: 'Mayer',\n",
       " 591: 'Shima',\n",
       " 592: 'Mojjis',\n",
       " 593: 'Svotchak',\n",
       " 594: 'Paiser',\n",
       " 595: 'Tomanek',\n",
       " 596: 'Ruda',\n",
       " 597: 'Trnkova',\n",
       " 598: 'Kober',\n",
       " 599: 'Whitmire1',\n",
       " 600: 'Patril',\n",
       " 601: 'Kosko',\n",
       " 602: 'Kurtz',\n",
       " 603: 'Hrdy',\n",
       " 604: 'Bohunovsky',\n",
       " 605: 'Pesek',\n",
       " 606: 'Ozimuk',\n",
       " 607: 'Kaplanek',\n",
       " 608: 'Pachr',\n",
       " 609: 'Jarzembowski',\n",
       " 610: 'Brousil',\n",
       " 611: 'Fojtikova',\n",
       " 612: 'Morava',\n",
       " 613: 'Hrabak',\n",
       " 614: 'Chromy',\n",
       " 615: 'Drassal',\n",
       " 616: 'Stegon',\n",
       " 617: 'Quasninsky',\n",
       " 618: 'Kenzel',\n",
       " 619: 'Siegl',\n",
       " 620: 'Monfort',\n",
       " 621: 'Stepan',\n",
       " 622: 'Wiesner',\n",
       " 623: 'Vlasak',\n",
       " 624: 'Schlantz',\n",
       " 625: 'Jirava',\n",
       " 626: 'Stramba',\n",
       " 627: 'Kuffel',\n",
       " 628: 'Blecha',\n",
       " 629: 'Rozinek',\n",
       " 630: 'Koukal',\n",
       " 631: 'Cablikova',\n",
       " 632: 'Silhan',\n",
       " 633: 'Kara',\n",
       " 634: 'Svejda',\n",
       " 635: 'Dopita',\n",
       " 636: 'Wykruta',\n",
       " 637: 'Planick',\n",
       " 638: 'Piller',\n",
       " 639: 'Mojzis',\n",
       " 640: 'Ransom',\n",
       " 641: 'Soucek',\n",
       " 642: 'Lawa',\n",
       " 643: 'Klein',\n",
       " 644: 'Subertova',\n",
       " 645: 'Jirik',\n",
       " 646: 'Kanak',\n",
       " 647: 'Lind',\n",
       " 648: 'Giersig',\n",
       " 649: 'Slezak',\n",
       " 650: 'Palzewicz',\n",
       " 651: 'Tikal',\n",
       " 652: 'Slepica',\n",
       " 653: 'Krawiec',\n",
       " 654: 'Chermak',\n",
       " 655: 'Bilek',\n",
       " 656: 'Jobst',\n",
       " 657: 'Frierdich',\n",
       " 658: 'Korycan',\n",
       " 659: 'Brezovjak',\n",
       " 660: 'Kofel',\n",
       " 661: 'Maly',\n",
       " 662: 'Marik',\n",
       " 663: 'Spoerl',\n",
       " 664: 'Prachar',\n",
       " 665: 'Gavalok',\n",
       " 666: 'Spicka',\n",
       " 667: 'Persein',\n",
       " 668: 'Koza',\n",
       " 669: 'Nadwornik',\n",
       " 670: 'Hradek',\n",
       " 671: 'Suchanka',\n",
       " 672: 'Betlach',\n",
       " 673: 'Perevuznik',\n",
       " 674: 'Tykal',\n",
       " 675: 'Soukup',\n",
       " 676: 'Divoky',\n",
       " 677: 'Vlasek',\n",
       " 678: 'Smith',\n",
       " 679: 'Rebka',\n",
       " 680: 'Kofron',\n",
       " 681: 'Urbanovska',\n",
       " 682: 'Weiss',\n",
       " 683: 'Hodoval',\n",
       " 684: 'Kusak',\n",
       " 685: 'Perina',\n",
       " 686: 'Vykruta',\n",
       " 687: 'Rzehak',\n",
       " 688: 'Panek',\n",
       " 689: 'Jirovy',\n",
       " 690: 'Kreutschmer',\n",
       " 691: 'Ritchie',\n",
       " 692: 'Wood',\n",
       " 693: 'Kopecky',\n",
       " 694: 'Opp',\n",
       " 695: 'Merta',\n",
       " 696: 'Petrezelka',\n",
       " 697: 'Schubert',\n",
       " 698: 'Maxa/B',\n",
       " 699: 'Werlla',\n",
       " 700: 'Treblik',\n",
       " 701: 'StrakaO',\n",
       " 702: 'Urbanek',\n",
       " 703: 'Navara',\n",
       " 704: 'Pech',\n",
       " 705: 'Ustohal',\n",
       " 706: 'Jelinek',\n",
       " 707: 'Pear',\n",
       " 708: 'Buchta',\n",
       " 709: 'Malec',\n",
       " 710: 'Hudecek',\n",
       " 711: 'Driml',\n",
       " 712: 'Svoboda',\n",
       " 713: 'Karlovsky',\n",
       " 714: 'Borovsky',\n",
       " 715: 'Stites',\n",
       " 716: 'Pavlik',\n",
       " 717: 'Daal',\n",
       " 718: 'Houtum',\n",
       " 719: 'Apeldoorn',\n",
       " 720: 'Laar',\n",
       " 721: 'Vennen',\n",
       " 722: 'Simonis',\n",
       " 723: 'Rompaye',\n",
       " 724: 'Snyder',\n",
       " 725: 'Specht',\n",
       " 726: 'Houte',\n",
       " 727: 'Smets',\n",
       " 728: 'Seeger',\n",
       " 729: 'Rademakers',\n",
       " 730: 'Rijnder',\n",
       " 731: 'Roijakker',\n",
       " 732: 'Penners',\n",
       " 733: 'Kranz',\n",
       " 734: 'Akkeren',\n",
       " 735: 'Koeman',\n",
       " 736: 'Haanraats',\n",
       " 737: 'Aalsburg',\n",
       " 738: 'Lucas',\n",
       " 739: 'Rooiakkers',\n",
       " 740: 'Haanrade',\n",
       " 741: 'Snyders',\n",
       " 742: 'Lyon',\n",
       " 743: 'Aalst',\n",
       " 744: 'Klerkx',\n",
       " 745: 'Nifterik',\n",
       " 746: 'Peij',\n",
       " 747: 'Ramecker',\n",
       " 748: 'Schoorel',\n",
       " 749: 'Houttum',\n",
       " 750: 'Kanne',\n",
       " 751: 'Daele',\n",
       " 752: 'Sneijders',\n",
       " 753: 'Kolen',\n",
       " 754: 'Tunneson',\n",
       " 755: 'Mulder',\n",
       " 756: 'Klerkse',\n",
       " 757: 'Meeuwessen',\n",
       " 758: 'Dale',\n",
       " 759: 'Veen',\n",
       " 760: 'Schoonraad',\n",
       " 761: 'Seghers',\n",
       " 762: 'Amstel',\n",
       " 763: 'Klerken',\n",
       " 764: 'Achthoven',\n",
       " 765: 'Ramaker',\n",
       " 766: 'Penner',\n",
       " 767: 'Theunissen',\n",
       " 768: 'Bueren',\n",
       " 769: 'Assen',\n",
       " 770: 'Hanraets',\n",
       " 771: 'Reynder',\n",
       " 772: 'Buren',\n",
       " 773: 'Dael',\n",
       " 774: 'Laren',\n",
       " 775: 'Pey',\n",
       " 776: 'Cann',\n",
       " 777: 'Silje',\n",
       " 778: 'Sneijder',\n",
       " 779: 'Nifterick',\n",
       " 780: 'Hautem',\n",
       " 781: 'Leeuwenhoek',\n",
       " 782: 'Agteren',\n",
       " 783: 'Penders',\n",
       " 784: 'Sevriens',\n",
       " 785: 'Offermans',\n",
       " 786: 'Denend',\n",
       " 787: 'Reinders',\n",
       " 788: 'Berg',\n",
       " 789: 'Lauwens',\n",
       " 790: 'Merckx',\n",
       " 791: 'Sneijer',\n",
       " 792: 'Klerx',\n",
       " 793: 'Roijakkers',\n",
       " 794: 'Rompuy',\n",
       " 795: 'Schuyler',\n",
       " 796: 'Michel',\n",
       " 797: 'Roggeveen',\n",
       " 798: 'Antwerp',\n",
       " 799: 'Romijn',\n",
       " 800: 'Rooijakkers',\n",
       " 801: 'Donk',\n",
       " 802: 'Can',\n",
       " 803: 'Kuipers',\n",
       " 804: 'Schoonenburg',\n",
       " 805: 'Ogterop',\n",
       " 806: 'Reinder',\n",
       " 807: 'Peerenboom',\n",
       " 808: 'Adrichem',\n",
       " 809: 'Smit',\n",
       " 810: 'Reijnder',\n",
       " 811: 'Vandroogenbroeck',\n",
       " 812: 'Romeijn',\n",
       " 813: 'Vann',\n",
       " 814: 'Schenck',\n",
       " 815: 'Niftrik',\n",
       " 816: 'Avest',\n",
       " 817: 'Mohren',\n",
       " 818: 'Rompaey',\n",
       " 819: 'Pender',\n",
       " 820: 'Meisner',\n",
       " 821: 'Smits',\n",
       " 822: 'Haenraets',\n",
       " 823: 'Seegers',\n",
       " 824: 'Hassel',\n",
       " 825: 'Sniders',\n",
       " 826: 'Schrijnemakers',\n",
       " 827: 'Mas',\n",
       " 828: 'Lauwers',\n",
       " 829: 'Haanraads',\n",
       " 830: 'Mooren',\n",
       " 831: 'Schneiders',\n",
       " 832: 'Sneiders',\n",
       " 833: 'Snell',\n",
       " 834: 'Simon',\n",
       " 835: 'Nagel',\n",
       " 836: 'Kloeter',\n",
       " 837: 'Kappel',\n",
       " 838: 'Middlesworth',\n",
       " 839: 'Asch',\n",
       " 840: 'Amersvoort',\n",
       " 841: 'Schorel',\n",
       " 842: 'Kuijpers',\n",
       " 843: 'Stoep',\n",
       " 844: 'Achteren',\n",
       " 845: 'Krantz',\n",
       " 846: 'Rossem',\n",
       " 847: 'Schneijder',\n",
       " 848: 'Paulissen',\n",
       " 849: 'Tholberg',\n",
       " 850: 'Rietveld',\n",
       " 851: 'Herten',\n",
       " 852: 'Peter',\n",
       " 853: 'Ophoven',\n",
       " 854: 'Rompaeij',\n",
       " 855: 'Aller',\n",
       " 856: 'Roosa',\n",
       " 857: 'Philips',\n",
       " 858: 'Hout',\n",
       " 859: 'Meeuwissen',\n",
       " 860: 'Severins',\n",
       " 861: 'Romijnders',\n",
       " 862: 'Kuiper',\n",
       " 863: 'Rooiakker',\n",
       " 864: 'Ryskamp',\n",
       " 865: 'Altena',\n",
       " 866: 'Ramaaker',\n",
       " 867: 'Ter',\n",
       " 868: 'Aggelen',\n",
       " 869: 'Rijnders',\n",
       " 870: 'Raske',\n",
       " 871: 'Rompa',\n",
       " 872: 'Andel',\n",
       " 873: 'Tillens',\n",
       " 874: 'Schneijders',\n",
       " 875: 'Marqueringh',\n",
       " 876: 'Rompaij',\n",
       " 877: 'Hautum',\n",
       " 878: 'Slootmaekers',\n",
       " 879: 'Kools',\n",
       " 880: 'Kloet',\n",
       " 881: 'Antwerpen',\n",
       " 882: 'Spiker',\n",
       " 883: 'Meeuwes',\n",
       " 884: 'Haanrath',\n",
       " 885: 'Severijns',\n",
       " 886: 'Schwarzenberg',\n",
       " 887: 'Kool',\n",
       " 888: 'Meeuweszen',\n",
       " 889: 'Snijder',\n",
       " 890: 'Althuis',\n",
       " 891: 'Peeters',\n",
       " 892: 'Houtem',\n",
       " 893: 'Seelen',\n",
       " 894: 'Snaaijer',\n",
       " 895: 'Canne',\n",
       " 896: 'Rutten',\n",
       " 897: 'Langbroek',\n",
       " 898: 'Horn',\n",
       " 899: 'Kollen',\n",
       " 900: 'Maes',\n",
       " 901: 'Baarle',\n",
       " 902: 'Schoorl',\n",
       " 903: 'Sanna',\n",
       " 904: 'Roosevelt',\n",
       " 905: 'Koumans',\n",
       " 906: 'Akker',\n",
       " 907: 'Koemans',\n",
       " 908: 'Richard',\n",
       " 909: 'Nelissen',\n",
       " 910: 'Rooijakker',\n",
       " 911: 'Reynders',\n",
       " 912: 'Spijker',\n",
       " 913: 'Middelburg',\n",
       " 914: 'Prinsen',\n",
       " 915: 'Vandale',\n",
       " 916: 'Kloeten',\n",
       " 917: 'Beek',\n",
       " 918: 'Snider',\n",
       " 919: 'Rompu',\n",
       " 920: 'Buggenum',\n",
       " 921: 'Kikkert',\n",
       " 922: 'Rossum',\n",
       " 923: 'Oorschot',\n",
       " 924: 'Daalen',\n",
       " 925: 'Venn',\n",
       " 926: 'Ramakers',\n",
       " 927: 'Rameckers',\n",
       " 928: 'Rumpade',\n",
       " 929: 'Ven',\n",
       " 930: 'Segers',\n",
       " 931: 'Klerks',\n",
       " 932: 'Maas',\n",
       " 933: 'Andringa',\n",
       " 934: 'Tunison',\n",
       " 935: 'Meeuwsen',\n",
       " 936: 'Muyskens',\n",
       " 937: 'Teunissen',\n",
       " 938: 'Leeuwenhoeck',\n",
       " 939: 'Aart',\n",
       " 940: 'Marquering',\n",
       " 941: 'Haenraats',\n",
       " 942: 'Vane',\n",
       " 943: 'Harker',\n",
       " 944: 'Croucher',\n",
       " 945: 'Roscoe',\n",
       " 946: 'Jenkin',\n",
       " 947: 'Sinha',\n",
       " 948: 'Hind',\n",
       " 949: 'Ewing',\n",
       " 950: 'Stout',\n",
       " 951: 'Keefe',\n",
       " 952: 'Lynes',\n",
       " 953: 'Plummer',\n",
       " 954: 'Seymour',\n",
       " 955: 'Hodder',\n",
       " 956: 'Grady',\n",
       " 957: 'Dawkins',\n",
       " 958: 'Whitmore',\n",
       " 959: 'Evans',\n",
       " 960: 'Mccall',\n",
       " 961: 'Peach',\n",
       " 962: 'Legg',\n",
       " 963: 'Keith',\n",
       " 964: 'Fowley',\n",
       " 965: 'Leyshon',\n",
       " 966: 'Caldwell',\n",
       " 967: 'Abraham',\n",
       " 968: 'Ashbridge',\n",
       " 969: 'Morgan',\n",
       " 970: 'Thurling',\n",
       " 971: 'Errity',\n",
       " 972: 'Mcavoy',\n",
       " 973: 'Turney',\n",
       " 974: 'Elphick',\n",
       " 975: 'Osmond',\n",
       " 976: 'Nurse',\n",
       " 977: 'Wears',\n",
       " 978: 'Fleming',\n",
       " 979: 'Santos',\n",
       " 980: 'Bush',\n",
       " 981: 'Fulker',\n",
       " 982: 'Prior',\n",
       " 983: 'Dumont',\n",
       " 984: 'Gulley',\n",
       " 985: 'Glossop',\n",
       " 986: 'Plumb',\n",
       " 987: 'Redman',\n",
       " 988: 'Wilson',\n",
       " 989: 'Hancock',\n",
       " 990: 'Willetts',\n",
       " 991: 'Oldham',\n",
       " 992: 'Owings',\n",
       " 993: 'Talbot',\n",
       " 994: 'Arrowsmith',\n",
       " 995: 'Kidner',\n",
       " 996: 'Smallwood',\n",
       " 997: 'Mather',\n",
       " 998: 'Browne',\n",
       " 999: 'Adlam',\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e172eee",
   "metadata": {},
   "source": [
    "### 국적 Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4669178c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Vocabulary at 0x7fb4d33f3610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nation_vocab = Vocabulary(add_unk=False)\n",
    "nation_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94b630e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic\n",
      "Chinese\n",
      "Czech\n",
      "Dutch\n",
      "English\n",
      "French\n",
      "German\n",
      "Greek\n",
      "Irish\n",
      "Italian\n",
      "Japanese\n",
      "Korean\n",
      "Polish\n",
      "Portuguese\n",
      "Russian\n",
      "Scottish\n",
      "Spanish\n",
      "Vietnamese\n"
     ]
    }
   ],
   "source": [
    "# 국적 Vocabulary 추가 \n",
    "\n",
    "for nation in sorted(set(df.nationality)):\n",
    "    nation_vocab.add_token(nation)\n",
    "    print(nation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bb67a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic': 0,\n",
       " 'Chinese': 1,\n",
       " 'Czech': 2,\n",
       " 'Dutch': 3,\n",
       " 'English': 4,\n",
       " 'French': 5,\n",
       " 'German': 6,\n",
       " 'Greek': 7,\n",
       " 'Irish': 8,\n",
       " 'Italian': 9,\n",
       " 'Japanese': 10,\n",
       " 'Korean': 11,\n",
       " 'Polish': 12,\n",
       " 'Portuguese': 13,\n",
       " 'Russian': 14,\n",
       " 'Scottish': 15,\n",
       " 'Spanish': 16,\n",
       " 'Vietnamese': 17}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nation_vocab.token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "caf7746c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Arabic',\n",
       " 1: 'Chinese',\n",
       " 2: 'Czech',\n",
       " 3: 'Dutch',\n",
       " 4: 'English',\n",
       " 5: 'French',\n",
       " 6: 'German',\n",
       " 7: 'Greek',\n",
       " 8: 'Irish',\n",
       " 9: 'Italian',\n",
       " 10: 'Japanese',\n",
       " 11: 'Korean',\n",
       " 12: 'Polish',\n",
       " 13: 'Portuguese',\n",
       " 14: 'Russian',\n",
       " 15: 'Scottish',\n",
       " 16: 'Spanish',\n",
       " 17: 'Vietnamese'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nation_vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd30e80",
   "metadata": {},
   "source": [
    "## 3. Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0720a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 토큰에 대응하는 인덱스 반환\n",
    "\n",
    "def lookup_token(vocabulary_class,token):\n",
    "\n",
    "# UNK 토큰이 있을 경우\n",
    "    if vocabulary_class.unk_index >= 0:\n",
    "#           토큰을 찾아보고 없으면 unk_index 반환, 있으면 해당 토큰의 idx를 반환\n",
    "        return vocabulary_class.token_to_idx.get(token, vocabulary_class.unk_index)\n",
    "    else:\n",
    "        return vocabulary_class.token_to_idx[token]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d025329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 인덱스에 대응하는 토큰 반환\n",
    "\n",
    "def lookup_index(vocabulary_class, index):\n",
    "        if index not in vocabulary_class.idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return vocabulary_class.idx_to_token[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11824f7",
   "metadata": {},
   "source": [
    "### 텍스트(surname)에 대한 원 핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e375f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "def vectorize(voca, column):\n",
    "\n",
    "#     전체 리뷰 사이즈만큼을 미리 0으로 채워둠\n",
    "    one_hot = np.zeros(len(voca.token_to_idx), dtype=np.float32)\n",
    "    one_hot\n",
    "    \n",
    "    for token in column.split(\" \"):\n",
    "        \n",
    "#         토큰이 .(구두점)이 아닐 경우 \n",
    "#         토큰에 해당되는 인덱스에 1를 부여한 one_hot encoding 만듦\n",
    "        if token not in string.punctuation:\n",
    "            one_hot[lookup_token(voca,token)] = 1\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "print(vectorize(name_vocab,\"all i can say is that a i had no other option\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b49a42",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7320e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NameDataset(Dataset):\n",
    "    def __init__(self, names, nations):\n",
    "        self.names = names\n",
    "        self.nations = nations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name = self.names[index]\n",
    "        nation = self.nations[index]\n",
    "        \n",
    "#         여기다가 vectorize함수 사용해서 name return\n",
    "        vectorized_name = vectorize(name_vocab,name)\n",
    "#       nation 숫자로 return\n",
    "#         vectorized_nation = vectorize(nation_vocab,nation)\n",
    "        vectorized_nation = lookup_token(nation_vocab,nation)\n",
    "    \n",
    "        return {\n",
    "            'surname': vectorized_name,\n",
    "            'nationality': vectorized_nation\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cae239",
   "metadata": {},
   "source": [
    "### 데이터셋 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14c6c27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NameDataset at 0x7fb4d34c6700>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋을 인스턴스화 해주어야 로더에 넣어줄 수 있다. \n",
    "\n",
    "train_dataset = NameDataset(train_df[\"surname\"].values, train_df[\"nationality\"].values)\n",
    "train_dataset\n",
    "\n",
    "valid_dataset = NameDataset(val_df[\"surname\"].values, val_df[\"nationality\"].values)\n",
    "valid_dataset\n",
    "\n",
    "test_dataset = NameDataset(test_df[\"surname\"].values, test_df[\"nationality\"].values)\n",
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9514135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 설정\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# drop_last=True -> 배치 사이즈보다 over하면 drop\n",
    "\n",
    "Traindataloader = DataLoader(dataset=train_dataset, batch_size=512,\n",
    "                            shuffle=True, drop_last=True)\n",
    "\n",
    "Validdataloader = DataLoader(dataset=valid_dataset, batch_size=512,\n",
    "                            shuffle=True, drop_last=True)\n",
    "\n",
    "Testdataloader = DataLoader(dataset=test_dataset, batch_size=512,\n",
    "                            shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e8a9d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7680 15\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset),len(Traindataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daefd63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'surname': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'nationality': tensor([ 4,  4, 14, 14,  9, 14, 14, 10,  4, 16,  4,  4,  0,  4, 14,  9,  9,  0,\n",
      "        14, 14,  4,  8,  0,  9,  4,  4,  6,  2,  8,  4,  6,  4,  7, 10, 10,  0,\n",
      "         4,  8,  4,  0, 10,  2, 14, 14, 16, 15, 14,  0,  8, 14,  4,  4,  0,  9,\n",
      "        14, 14,  4, 14, 14, 14,  6, 12,  5, 10, 10,  4,  4,  4,  4,  0, 10,  4,\n",
      "         4, 13,  0,  0,  3,  0,  4, 14,  9,  6, 14, 14,  0,  0, 10,  5, 14,  4,\n",
      "        12,  4,  3,  0, 14,  4,  6,  6,  2, 14, 12,  9,  0,  9,  4, 14,  0, 14,\n",
      "        13, 10,  2, 10, 14,  4,  6,  9,  0, 14,  4, 17,  0, 14,  4,  0,  4, 14,\n",
      "         6,  4,  4,  1,  4, 10, 16, 14,  0,  0, 10,  9,  9,  9,  0,  9,  4,  4,\n",
      "         1,  4, 14,  4, 10,  9, 14, 14, 14,  4, 15,  4,  5,  5, 14,  6,  4,  4,\n",
      "         4,  4,  0,  6,  4,  6,  1, 10,  4,  9, 15,  3,  0,  0, 16,  4, 14, 14,\n",
      "        14,  9,  5, 14, 14, 14, 14,  0,  9,  4,  4,  4,  6,  4,  9, 14,  4,  1,\n",
      "        14, 14,  4, 10,  4, 14, 14,  0,  4, 14,  2, 14,  4,  9,  6, 10,  5, 14,\n",
      "         9,  4,  0,  0,  9,  4,  4, 10,  3, 14, 14,  4,  4,  8,  4, 14,  2,  4,\n",
      "         2,  4,  4,  6,  0,  9, 14,  4,  6,  0, 14,  4,  9,  3, 16, 16,  0,  4,\n",
      "         0,  4,  9, 12,  0,  2,  4,  9,  0, 16,  4,  4, 14, 14,  4,  0,  9, 10,\n",
      "        10, 14,  4, 14,  0,  4, 14,  0,  0, 10,  0, 14, 17,  9,  5,  9,  6, 14,\n",
      "         0,  6,  4,  0,  0, 14,  4,  8,  4, 10,  0, 13, 14,  4,  4, 14, 14, 16,\n",
      "         4, 10,  1,  2,  3,  7,  2,  0,  4,  0,  2,  1,  0,  3,  6, 16,  6, 10,\n",
      "        10,  0,  2, 14,  4,  4,  4, 14,  4,  4, 10, 14,  4, 14, 14,  4,  0,  0,\n",
      "         0,  4,  0,  0,  4,  4,  9,  4, 14,  3, 14, 10,  4, 14, 15,  4,  9,  0,\n",
      "         0, 10, 14,  4, 14,  4,  0,  4, 12,  0, 14,  2,  4, 10, 14,  4,  4,  4,\n",
      "        14,  9, 14,  6, 14,  4,  3, 14, 14,  0,  4,  4,  0,  9, 12,  7,  0,  4,\n",
      "        14, 14, 10,  4, 14, 14,  4,  0,  6,  4,  0,  7, 14, 16, 14,  3,  4, 14,\n",
      "         9,  4,  2,  4, 14,  0,  0,  4, 17, 14,  4, 10,  9,  6,  4,  4,  4, 14,\n",
      "         4,  0,  6,  8,  7,  2, 14, 14,  3,  4,  4,  0, 14, 14, 14,  0,  6,  4,\n",
      "        14,  4, 10, 14,  8, 10, 14,  3,  9,  0,  5, 14, 14,  9, 10,  9,  4,  7,\n",
      "         5, 10, 14, 10,  9,  2, 14,  4,  0, 14,  4, 14,  4,  4,  9,  7,  4,  4,\n",
      "         4,  6,  0, 14,  4, 14, 14,  9,  0,  4,  4, 10, 10,  0,  0,  9, 14, 14,\n",
      "         3,  0, 10,  5,  4,  8,  0, 10])}\n"
     ]
    }
   ],
   "source": [
    "for batch_index, batch_dict in enumerate(Traindataloader):\n",
    "    print(batch_index)\n",
    "    print(batch_dict)\n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ecfdb1",
   "metadata": {},
   "source": [
    "### 모델 정의 및 옵티마이저, loss func 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f87bef",
   "metadata": {},
   "source": [
    "### 모델정의 ReviewClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0278b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn은 neural network로 torch의 신경망 모듈이다.\n",
    "# MLP사용 \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NameClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "#       torch.nn.Module의 초기화 메서드를 실행하여 해당 클래스의 기능을 상속받음\n",
    "        super(NameClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim,output_dim)\n",
    "    \n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        intermediate = F.relu(self.fc1(x_in))\n",
    "        output = self.fc2(intermediate)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            output = F.softmax(output,dim=1)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27e42c",
   "metadata": {},
   "source": [
    "### 드롭 아웃 적용한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ca541f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn은 neural network로 torch의 신경망 모듈이다.\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NameClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "#       torch.nn.Module의 초기화 메서드를 실행하여 해당 클래스의 기능을 상속받음\n",
    "        super(NameClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim,output_dim)\n",
    "    \n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        intermediate = F.relu(self.fc1(x_in))\n",
    "        output = self.fc2(F.dropout(intermediate,p=0.5))\n",
    "        \n",
    "        if apply_softmax:\n",
    "            output = F.softmax(output,dim=1)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf8c0292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9042"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name_vocab.token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3521990e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nation_vocab.token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37fcc4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NameClassifier(\n",
       "  (fc1): Linear(in_features=9042, out_features=300, bias=True)\n",
       "  (fc2): Linear(in_features=300, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim = 300\n",
    "\n",
    "classifier = NameClassifier(input_dim=len(name_vocab.token_to_idx),\n",
    "                            hidden_dim=hidden_dim,\n",
    "                           output_dim=len(nation_vocab.token_to_idx))\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d622c",
   "metadata": {},
   "source": [
    "### 옵티마이저, loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "330f6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59b5517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 옵티마이저\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr = lr)\n",
    "optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "065a7109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nationality\n",
       "English       2972\n",
       "Russian       2373\n",
       "Arabic        1603\n",
       "Japanese       775\n",
       "Italian        600\n",
       "German         576\n",
       "Czech          414\n",
       "Spanish        258\n",
       "Dutch          236\n",
       "French         229\n",
       "Chinese        220\n",
       "Irish          183\n",
       "Greek          156\n",
       "Polish         120\n",
       "Korean          77\n",
       "Scottish        75\n",
       "Vietnamese      58\n",
       "Portuguese      55\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['nationality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0def7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7293, 0.7839, 0.8540, 0.9294, 0.9454, 0.9475, 0.9623, 0.9765, 0.9785,\n",
       "        0.9791, 0.9800, 0.9833, 0.9858, 0.9891, 0.9930, 0.9932, 0.9947, 0.9950])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numSample_list = df['nationality'].value_counts().tolist()\n",
    "numSample_list\n",
    "# weights 계산\n",
    "weights = [1 - (x / sum(numSample_list)) for x in numSample_list]\n",
    "\n",
    "# weights를 torch.FloatTensor로 변환\n",
    "weights = torch.FloatTensor(weights)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b56190b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss function\n",
    "#  dataset.class_weights -> 각 클래스에 대해 다른 가중치를 적용할 수 있음(데이터 불균형시에)\n",
    "# 소수의 클래스가 다수의 클래스보다 훨씬 적은 수의 샘플을 가지고 있는 경우, \n",
    "# 소수 클래스에 더 높은 가중치를 부여하여 모델이 불균형한 데이터에 대해 더 잘 학습\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(weights)\n",
    "loss_func\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3781e8c8",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e515293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_target):\n",
    "#      예측값과 타겟값을 비교하여 일치하는 개수를 계산\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8427c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train state 초기화 \n",
    "def make_train_state():\n",
    "    return {\n",
    "        'stop_early':False,\n",
    "        'early_stopping_step':0,\n",
    "        'early_stopping_best_val':1e8,\n",
    "        'early_stopping_criteria' : 10,\n",
    "        'epoch_index' : 0,\n",
    "        'train_loss': [], \n",
    "        'train_acc' :[], \n",
    "        'val_loss' : [],\n",
    "        'val_acc' : [], \n",
    "        'test_loss' : [],\n",
    "        'test_acc' : [],\n",
    "         \n",
    "#       모델 저장파일\n",
    "        'model_filename' : 'model.pth'\n",
    "    } \n",
    "\n",
    "\n",
    "# Train update \n",
    "def update_train_state(model, train_state):\n",
    "    \n",
    "#   학습시작하면 초기에 모델 저장하기 \n",
    "    \n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(),train_state['model_filename'])\n",
    "        \n",
    "#   모델 성능이 향상되면 모델 저장(valid loss가 더 낮아지면)\n",
    "    elif train_state['epoch_index'] >=1 :\n",
    "        loss_t = train_state['val_loss'][-1]\n",
    "#        loss가 나빠지면 early stop step 업데이트\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            train_state['early_stopping_step']+=1\n",
    "            \n",
    "#        loss가 좋아지면   \n",
    "        else:\n",
    "#            early stop step 0으로 다시 초기화        \n",
    "            train_state['early_stopping_step']=0\n",
    "    \n",
    "#           최저 loss이면 모델 저장 \n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "                torch.save(model.state_dict(),train_state['model_filename'])\n",
    "\n",
    "#       기준점 넘으면 early stop \n",
    "        if train_state['early_stopping_step'] >= train_state['early_stopping_criteria']:\n",
    "            train_state['stop_early'] = True\n",
    "        \n",
    "        return train_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87458bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_early': False,\n",
       " 'early_stopping_step': 0,\n",
       " 'early_stopping_best_val': 100000000.0,\n",
       " 'early_stopping_criteria': 10,\n",
       " 'epoch_index': 0,\n",
       " 'train_loss': [],\n",
       " 'train_acc': [],\n",
       " 'val_loss': [],\n",
       " 'val_acc': [],\n",
       " 'test_loss': [],\n",
       " 'test_acc': [],\n",
       " 'model_filename': 'model.pth'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 진행 상황 함수 초기화\n",
    "train_state = make_train_state()\n",
    "train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "550eb7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                          | 1/100 [00:01<03:02,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8252743085225425\n",
      "val_acc 15.169270833333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                          | 2/100 [00:03<02:40,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.6660370031992593\n",
      "val_acc 33.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▎                                         | 3/100 [00:04<02:35,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.42344339688619\n",
      "val_acc 34.895833333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▋                                         | 4/100 [00:06<02:33,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.2233364582061768\n",
      "val_acc 27.473958333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██▏                                        | 5/100 [00:08<02:30,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.1553154786427817\n",
      "val_acc 27.669270833333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▌                                        | 6/100 [00:09<02:25,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.123735268910726\n",
      "val_acc 35.872395833333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|███                                        | 7/100 [00:11<02:22,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.0613616704940796\n",
      "val_acc 41.145833333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▍                                       | 8/100 [00:12<02:18,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.0356032053629556\n",
      "val_acc 41.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▊                                       | 9/100 [00:14<02:19,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9932376941045125\n",
      "val_acc 41.731770833333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▏                                     | 10/100 [00:15<02:17,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9527780612309773\n",
      "val_acc 41.2109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▌                                     | 11/100 [00:17<02:15,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9177780946095784\n",
      "val_acc 41.731770833333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████                                     | 12/100 [00:18<02:11,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9209449291229248\n",
      "val_acc 41.2109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████▍                                    | 13/100 [00:20<02:12,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.909353494644165\n",
      "val_acc 39.908854166666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▉                                    | 14/100 [00:22<02:20,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.903205116589864\n",
      "val_acc 40.690104166666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▎                                   | 15/100 [00:23<02:25,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.911732792854309\n",
      "val_acc 42.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████▋                                   | 16/100 [00:25<02:30,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9057999451955159\n",
      "val_acc 42.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████▏                                  | 17/100 [00:27<02:21,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9144363403320312\n",
      "val_acc 42.7734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████▌                                  | 18/100 [00:29<02:22,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.92490021387736\n",
      "val_acc 42.643229166666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████▉                                  | 19/100 [00:31<02:25,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9463210503260295\n",
      "val_acc 41.080729166666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▍                                 | 20/100 [00:33<02:26,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9434895118077595\n",
      "val_acc 41.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████▊                                 | 21/100 [00:34<02:22,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9605814615885417\n",
      "val_acc 40.755208333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████▏                                | 22/100 [00:36<02:13,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9811700582504272\n",
      "val_acc 41.341145833333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████▋                                | 23/100 [00:37<02:05,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9675931930541992\n",
      "val_acc 42.513020833333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████▋                                | 23/100 [00:39<02:11,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 1.9982776641845703\n",
      "val_acc 41.536458333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# 에포크만큼\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "\n",
    "#     print('epoch',epoch)\n",
    "#     print(train_state['epoch_index']) \n",
    "    train_state['epoch_index'] +=1 \n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "\n",
    "#     모델을 학습 모드로 설정 -> 드롭아웃 및 배치 정규화와 같은 학습 중에만 적용되는 기법들이 활성화\n",
    "#     모델을 평가 모드로 전환하려면 classifier.eval()을 사용\n",
    "    classifier.train()\n",
    "# 배치 만큼\n",
    "    for batch_idx, batch_data in enumerate(Traindataloader):\n",
    "\n",
    "        \n",
    "\n",
    "#       1. 옵티마이저 그레디언트 0으로 초기화\n",
    "        optimizer.zero_grad()\n",
    "#       2. 모델에 데이터 넣어서 출력받기\n",
    "        y_pred = classifier(x_in=batch_data['surname'])\n",
    "#       3. loss 계산하기\n",
    "        loss =  loss_func(y_pred, batch_data['nationality'])\n",
    "    \n",
    "#       tensor(0.3190) -> 0.3190, item()으로 스칼라 값만 추출\n",
    "        loss_t = loss.item()\n",
    "\n",
    "#       배치에서의 평균 loss 구하기\n",
    "        running_loss += (loss_t - running_loss) / (batch_idx + 1)\n",
    "\n",
    "#       4. gradient 계산하기\n",
    "        loss.backward()\n",
    "\n",
    "#       5. 옵티마이저 가중치 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "#       Accuracy 계산\n",
    "        acc_t = compute_accuracy(y_pred, batch_data['nationality'])\n",
    "        running_acc += (acc_t - running_acc) / (batch_idx + 1)\n",
    "\n",
    "\n",
    "\n",
    "    train_state['train_loss'].append(running_loss)\n",
    "    train_state['train_acc'].append(running_acc)\n",
    "\n",
    "\n",
    "#   valid에 대한 계산\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "    classifier.eval() # 모델 파라미터를 수정하지 못 하게 비활성화\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(Validdataloader):\n",
    "\n",
    "#       1. 모델의 출력값(y_pred)계산\n",
    "        y_pred = classifier(x_in=batch_data['surname'])\n",
    "\n",
    "#       2. loss 계산\n",
    "        loss = loss_func(y_pred,batch_data['nationality'])\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_idx + 1)\n",
    "\n",
    "#       3. Accuracy 계산\n",
    "        acc_t = compute_accuracy(y_pred,batch_data['nationality'])\n",
    "        running_acc += (acc_t - running_acc) / (batch_idx + 1)\n",
    "    \n",
    "    print(\"val_loss\",running_loss)\n",
    "    print(\"val_acc\",running_acc)\n",
    "\n",
    "    train_state['val_loss'].append(running_loss)\n",
    "    train_state['val_acc'].append(running_acc)\n",
    "    \n",
    "\n",
    "#   전체 loss, acc 저장\n",
    "    train_state = update_train_state(model=classifier,\n",
    "                                     train_state=train_state)\n",
    "#   early stop해라고 했으면 학습 멈추기    \n",
    "    if train_state['stop_early']:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81148c1c",
   "metadata": {},
   "source": [
    "### Test 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c570a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델을 사용해 테스트 세트의 손실과 정확도를 계산합니다\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
    "\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "\n",
    "# 가중치 업데이트 하지 못 하게\n",
    "classifier.eval()\n",
    "\n",
    "for batch_idx, batch_data in enumerate(Testdataloader):\n",
    "    \n",
    "    y_pred = classifier(x_in=batch_data['surname'])\n",
    "    loss = loss_func(y_pred,batch_data['nationality'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_idx + 1)\n",
    "    \n",
    "    acc_t = compute_accuracy(y_pred, batch_data['nationality'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_idx + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4576ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 손실: 1.931\n",
      "테스트 정확도: 40.82\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 손실: {:.3f}\".format(train_state['test_loss']))\n",
    "print(\"테스트 정확도: {:.2f}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64e5655b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_early': True,\n",
       " 'early_stopping_step': 10,\n",
       " 'early_stopping_best_val': 1.903205116589864,\n",
       " 'early_stopping_criteria': 10,\n",
       " 'epoch_index': 24,\n",
       " 'train_loss': [2.8662541389465335,\n",
       "  2.7537015279134116,\n",
       "  2.5309797128041587,\n",
       "  2.2651388963063552,\n",
       "  2.1040698051452638,\n",
       "  2.008525323867798,\n",
       "  1.9041026989618937,\n",
       "  1.790707572301229,\n",
       "  1.6639065821965535,\n",
       "  1.5314770062764487,\n",
       "  1.3943700393040976,\n",
       "  1.2507047812143959,\n",
       "  1.111471382776896,\n",
       "  0.9782052159309388,\n",
       "  0.8578760425249735,\n",
       "  0.7463638663291932,\n",
       "  0.6523718317349751,\n",
       "  0.5717738866806031,\n",
       "  0.5038931707541149,\n",
       "  0.4438691755135855,\n",
       "  0.39415636857350667,\n",
       "  0.3524436811606089,\n",
       "  0.3109319766362508,\n",
       "  0.28348709146181744],\n",
       " 'train_acc': [12.786458333333334,\n",
       "  27.669270833333336,\n",
       "  47.1875,\n",
       "  39.96093750000001,\n",
       "  32.91666666666667,\n",
       "  30.546875,\n",
       "  41.848958333333336,\n",
       "  49.28385416666667,\n",
       "  57.044270833333336,\n",
       "  60.625,\n",
       "  63.60677083333333,\n",
       "  69.59635416666667,\n",
       "  78.58072916666667,\n",
       "  82.64322916666666,\n",
       "  84.89583333333333,\n",
       "  87.04427083333333,\n",
       "  90.5078125,\n",
       "  93.34635416666667,\n",
       "  94.36197916666667,\n",
       "  95.15624999999999,\n",
       "  95.50781250000001,\n",
       "  95.84635416666667,\n",
       "  95.96354166666666,\n",
       "  96.09375000000001],\n",
       " 'val_loss': [2.8252743085225425,\n",
       "  2.6660370031992593,\n",
       "  2.42344339688619,\n",
       "  2.2233364582061768,\n",
       "  2.1553154786427817,\n",
       "  2.123735268910726,\n",
       "  2.0613616704940796,\n",
       "  2.0356032053629556,\n",
       "  1.9932376941045125,\n",
       "  1.9527780612309773,\n",
       "  1.9177780946095784,\n",
       "  1.9209449291229248,\n",
       "  1.909353494644165,\n",
       "  1.903205116589864,\n",
       "  1.911732792854309,\n",
       "  1.9057999451955159,\n",
       "  1.9144363403320312,\n",
       "  1.92490021387736,\n",
       "  1.9463210503260295,\n",
       "  1.9434895118077595,\n",
       "  1.9605814615885417,\n",
       "  1.9811700582504272,\n",
       "  1.9675931930541992,\n",
       "  1.9982776641845703],\n",
       " 'val_acc': [15.169270833333334,\n",
       "  33.59375,\n",
       "  34.895833333333336,\n",
       "  27.473958333333332,\n",
       "  27.669270833333332,\n",
       "  35.872395833333336,\n",
       "  41.145833333333336,\n",
       "  41.666666666666664,\n",
       "  41.731770833333336,\n",
       "  41.2109375,\n",
       "  41.731770833333336,\n",
       "  41.2109375,\n",
       "  39.908854166666664,\n",
       "  40.690104166666664,\n",
       "  42.1875,\n",
       "  42.96875,\n",
       "  42.7734375,\n",
       "  42.643229166666664,\n",
       "  41.080729166666664,\n",
       "  41.666666666666664,\n",
       "  40.755208333333336,\n",
       "  41.341145833333336,\n",
       "  42.513020833333336,\n",
       "  41.536458333333336],\n",
       " 'test_loss': 1.9313379923502605,\n",
       " 'test_acc': 40.8203125,\n",
       " 'model_filename': 'model.pth'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501556c",
   "metadata": {},
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5da50566",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_surname = \"Kim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4260192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터화 + 텐서화\n",
    "\n",
    "vectorized_surname = torch.tensor(vectorize(name_vocab,new_surname))\n",
    "vectorized_surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7ac8fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9042])\n"
     ]
    }
   ],
   "source": [
    "print(vectorized_surname.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d3e581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9042])\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 차원을 1로 만들고, 나머지는 다른 차원으로 알아서 되도록 !\n",
    "x_data = vectorized_surname.view(1, -1)\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33855a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0221, 0.0546, 0.0646, 0.0541, 0.0962, 0.0577, 0.0853, 0.0434, 0.0438,\n",
      "         0.0837, 0.1167, 0.0345, 0.0370, 0.0220, 0.0719, 0.0253, 0.0667, 0.0204]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 모델에 test 데이터 넣어주기\n",
    "result = classifier(x_data,apply_softmax=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "071d7992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1167, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3be11b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability_value tensor([0.1167], grad_fn=<MaxBackward0>)\n",
      "indices tensor([10])\n"
     ]
    }
   ],
   "source": [
    "probability_value, indices = result.max(dim=1)\n",
    "\n",
    "print(\"probability_value\",probability_value)\n",
    "print(\"indices\",indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3a3b0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 데이터에 대해 추론한 label 10\n"
     ]
    }
   ],
   "source": [
    "print(\"새로운 데이터에 대해 추론한 label\",indices.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f78ba3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Japanese'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = lookup_index(nation_vocab,indices.item())\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4dc3563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kim -> Japanese\n"
     ]
    }
   ],
   "source": [
    "print(\"{} -> {}\".format(new_surname, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac0f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4747a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
