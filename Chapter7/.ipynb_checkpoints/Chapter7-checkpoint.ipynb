{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ba4e86",
   "metadata": {},
   "source": [
    "# 예제: CNN으로 성씨 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbb0140",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962715ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nationality</th>\n",
       "      <th>nationality_index</th>\n",
       "      <th>split</th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Totah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Abboud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Fakhoury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Srour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Sayegh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Dinh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Phung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Quang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Vu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Ha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nationality  nationality_index  split   surname\n",
       "0          Arabic                 15  train     Totah\n",
       "1          Arabic                 15  train    Abboud\n",
       "2          Arabic                 15  train  Fakhoury\n",
       "3          Arabic                 15  train     Srour\n",
       "4          Arabic                 15  train    Sayegh\n",
       "...           ...                ...    ...       ...\n",
       "10975  Vietnamese                 11   test      Dinh\n",
       "10976  Vietnamese                 11   test     Phung\n",
       "10977  Vietnamese                 11   test     Quang\n",
       "10978  Vietnamese                 11   test        Vu\n",
       "10979  Vietnamese                 11   test        Ha\n",
       "\n",
       "[10980 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/surnames_with_splits.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f706d137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    7680\n",
       "test     1660\n",
       "val      1640\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f63e53",
   "metadata": {},
   "source": [
    "### 데이터 split(train/valid/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2795b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 다시 train/valid/test로 나눠줌\n",
    "\n",
    "# train 데이터 \n",
    "train_df = df[df.split=='train']\n",
    "train_size = len(train_df)\n",
    "\n",
    "# valid 데이터 \n",
    "val_df = df[df.split=='val']\n",
    "val_size = len(val_df)\n",
    "\n",
    "# test 데이터 \n",
    "test_df = df[df.split=='test']\n",
    "test_size = len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4447bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = {'train': (train_df, train_size), \n",
    "              'val': (val_df, val_size), \n",
    "              'test': (test_df, test_size)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf85816",
   "metadata": {},
   "source": [
    "## 2. Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1141fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, token_to_idx=None):\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self.token_to_idx = token_to_idx\n",
    "\n",
    "        self.idx_to_token = {idx: token \n",
    "                              for token, idx in self.token_to_idx.items()}\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \n",
    "#       만약 해당 토큰이 있으면 토큰 idx만 return\n",
    "        if token in self.token_to_idx:\n",
    "            index = self.token_to_idx[token]\n",
    "            \n",
    "#       만약 해당 토큰이 없으면 새로운 토큰 만들어줌\n",
    "        else:\n",
    "            index = len(self.token_to_idx)\n",
    "            self.token_to_idx[token] = index\n",
    "            self.idx_to_token[index] = token\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99bf9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056f721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab 생성\n",
    "char_vocab = SequenceVocabulary()\n",
    "nationality_vocab = Vocabulary()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for char in row.surname:\n",
    "        char_vocab.add_token(char)\n",
    "    nationality_vocab.add_token(row.nationality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77aef3c",
   "metadata": {},
   "source": [
    "### Char Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d51f439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'T': 4, 'o': 5, 't': 6, 'a': 7, 'h': 8, 'A': 9}\n"
     ]
    }
   ],
   "source": [
    "print(dict(list(char_vocab.token_to_idx.items())[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4659251",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<MASK>', 1: '<UNK>', 2: '<BEGIN>', 3: '<END>', 4: 'T', 5: 'o', 6: 't', 7: 'a', 8: 'h', 9: 'A'}\n"
     ]
    }
   ],
   "source": [
    "print(dict(list(char_vocab.idx_to_token.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd30e80",
   "metadata": {},
   "source": [
    "## 3. Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0720a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 토큰에 대응하는 인덱스 반환\n",
    "\n",
    "def lookup_token(vocabulary_class,token):\n",
    "    return vocabulary_class.token_to_idx[token]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d025329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 인덱스에 대응하는 토큰 반환\n",
    "\n",
    "def lookup_index(vocabulary_class, index):\n",
    "        if index not in vocabulary_class.idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return vocabulary_class.idx_to_token[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e09e6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰의 수: 88\n"
     ]
    }
   ],
   "source": [
    "vocab_length = len(char_vocab.token_to_idx)\n",
    "print(\"토큰의 수:\", vocab_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11824f7",
   "metadata": {},
   "source": [
    "### 텍스트(surname)에 대한 원 핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e375f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예시\n",
      "(array([ 2, 20,  8,  5, 23,  0,  0,  0,  0,  0]), array([20,  8,  5, 23,  3,  0,  0,  0,  0,  0]))\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# vector_length (int): 인덱스 벡터의 길이를 맞추기 위한 매개변수\n",
    "def vectorize(surname, vector_length=-1):\n",
    "\n",
    "    indices = [char_vocab.begin_seq_index]\n",
    "    indices.extend(lookup_token(char_vocab,token) \n",
    "                   for token in surname)\n",
    "    indices.append(char_vocab.end_seq_index)\n",
    "\n",
    "    if vector_length < 0:\n",
    "        vector_length = len(indices)\n",
    "    \n",
    "    from_vector = np.empty(vector_length, dtype=np.int64)         \n",
    "    from_indices = indices[:-1]\n",
    "    from_vector[:len(from_indices)] = from_indices\n",
    "    from_vector[len(from_indices):] = char_vocab.mask_index\n",
    "\n",
    "    to_vector = np.empty(vector_length, dtype=np.int64)\n",
    "    to_indices = indices[1:]\n",
    "    to_vector[:len(to_indices)] = to_indices\n",
    "    to_vector[len(to_indices):] = char_vocab.mask_index\n",
    "        \n",
    "    return from_vector, to_vector\n",
    "\n",
    "print(\"예시\")\n",
    "example = vectorize(\"Choi\", 10)\n",
    "print(example)\n",
    "print(len(example[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b49a42",
   "metadata": {},
   "source": [
    "### SurnameDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7320e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SurnameDataset(Dataset):\n",
    "    def __init__(self, surname_df):\n",
    "        self.surname_df = surname_df\n",
    "        self.max_seq_length = max(map(len, df.surname)) + 2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.surname_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.surname_df.iloc[index]\n",
    "        \n",
    "        from_vector, to_vector = vectorize(row.surname, self.max_seq_length)\n",
    "\n",
    "        return {'x_data': from_vector, \n",
    "                'y_target': to_vector}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cae239",
   "metadata": {},
   "source": [
    "### 데이터셋 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c6c27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SurnameDataset at 0x7fe3e96e4550>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋을 인스턴스화 해주어야 로더에 넣어줄 수 있다. \n",
    "\n",
    "train_dataset = SurnameDataset(train_df)\n",
    "train_dataset\n",
    "\n",
    "valid_dataset = SurnameDataset(val_df)\n",
    "valid_dataset\n",
    "\n",
    "test_dataset = SurnameDataset(test_df)\n",
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfe60fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.max_seq_length)\n",
    "print(valid_dataset.max_seq_length)\n",
    "print(test_dataset.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9514135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 설정\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# drop_last=True -> 배치 사이즈보다 over하면 drop\n",
    "\n",
    "Traindataloader = DataLoader(dataset=train_dataset, batch_size=512,\n",
    "                            shuffle=True, drop_last=True)\n",
    "\n",
    "Validdataloader = DataLoader(dataset=valid_dataset, batch_size=512,\n",
    "                            shuffle=True, drop_last=True)\n",
    "\n",
    "Testdataloader = DataLoader(dataset=test_dataset, batch_size=512,\n",
    "                            shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e8a9d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7680 15\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset),len(Traindataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daefd63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_data': tensor([[ 2,  4,  5,  ...,  0,  0,  0],\n",
      "        [ 2,  9, 10,  ...,  0,  0,  0],\n",
      "        [ 2, 13,  5,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 2, 29, 11,  ...,  0,  0,  0],\n",
      "        [ 2, 44,  7,  ...,  0,  0,  0],\n",
      "        [ 2, 26,  7,  ...,  0,  0,  0]]), 'y_target': tensor([[ 4,  5, 25,  ...,  0,  0,  0],\n",
      "        [ 9, 10,  7,  ...,  0,  0,  0],\n",
      "        [13,  5, 21,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [29, 11, 18,  ...,  0,  0,  0],\n",
      "        [44,  7, 25,  ...,  0,  0,  0],\n",
      "        [26,  7, 15,  ...,  0,  0,  0]])}\n"
     ]
    }
   ],
   "source": [
    "for batch_index, batch_dict in enumerate(Traindataloader):\n",
    "#     print(batch_index)\n",
    "    print(batch_dict)\n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ecfdb1",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "addd5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 정의 함수\n",
    "# 주어진 배치의 각 데이터 포인트에 대해 시퀀스의 마지막 벡터를 추출\n",
    "# => y_out에 있는 각 데이터 포인트에서 마지막 벡터 추출\n",
    "def column_gather(y_out, x_lengths):\n",
    "    \n",
    "#     x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "    x_lengths = x_lengths-1\n",
    "    out = []\n",
    "    for batch_index, length in enumerate(x_lengths):\n",
    "        out.append(y_out[batch_index, length])\n",
    "\n",
    "    return torch.stack(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb17bb",
   "metadata": {},
   "source": [
    "### column_gather 출력예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77085ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8,  9],\n",
      "        [16, 17, 18]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 가상의 입력 데이터\n",
    "y_out = torch.tensor([\n",
    "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],  # 첫 번째 시퀀스: 길이 3\n",
    "    [[10, 11, 12], [13, 14, 15], [16, 17, 18]],  # 두 번째 시퀀스: 길이 3 (길이를 맞춤)\n",
    "])\n",
    "\n",
    "x_lengths = torch.tensor([3, 3])  # 각 시퀀스의 길이 (동일하게 맞춤)\n",
    "# column_gather 함수 호출\n",
    "result = column_gather(y_out, x_lengths)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85871c4a",
   "metadata": {},
   "source": [
    "### 조건이 없는 성씨 생성 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0278b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "import torch.nn as nn\n",
    "\n",
    "class SurnameGenerationModel(nn.Module):\n",
    "    def __init__(self, char_embedding_size, char_vocab_size, rnn_hidden_size, \n",
    "                 batch_first=True, padding_idx=0, dropout_p=0.5):\n",
    "        \n",
    "        super(SurnameGenerationModel, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings = char_vocab_size,\n",
    "                               embedding_dim = char_embedding_size,\n",
    "                               padding_idx = padding_idx)\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=char_embedding_size, \n",
    "                          hidden_size=rnn_hidden_size,\n",
    "                          batch_first=batch_first)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=rnn_hidden_size, \n",
    "                            out_features=char_vocab_size)\n",
    "        \n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        x_embedded = self.emb(x_in)\n",
    "\n",
    "        y_out, _ = self.rnn(x_embedded)\n",
    "\n",
    "        batch_size, seq_size, feat_size = y_out.shape\n",
    "        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
    "\n",
    "        y_out = self.fc(F.dropout(y_out, p=self.dropout_p))\n",
    "                         \n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "            \n",
    "        new_feat_size = y_out.shape[-1]\n",
    "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
    "            \n",
    "        return y_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf8c0292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_vocab.token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3521990e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nationality_vocab.token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37fcc4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurnameGenerationModel(\n",
       "  (emb): Embedding(88, 32, padding_idx=0)\n",
       "  (rnn): GRU(32, 32, batch_first=True)\n",
       "  (fc): Linear(in_features=32, out_features=88, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_embedding_size = 32\n",
    "rnn_hidden_size = 32\n",
    "\n",
    "model = SurnameGenerationModel(char_embedding_size=char_embedding_size,\n",
    "                               char_vocab_size=len(char_vocab.token_to_idx),\n",
    "                               rnn_hidden_size=rnn_hidden_size,\n",
    "                               padding_idx=char_vocab.mask_index)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde52822",
   "metadata": {},
   "source": [
    "### 모델 뜯어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95c419f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미니배치 0의 임베딩 결과:\n",
      "torch.Size([512, 19, 32])\n",
      "tensor([[[-1.6768, -0.1081, -0.3991,  ..., -0.8560,  0.2349, -1.7395],\n",
      "         [-0.7472, -0.4895, -0.9260,  ..., -1.1073,  0.1093, -0.8658],\n",
      "         [ 0.9645,  0.2061,  0.6376,  ...,  0.1630, -1.1543, -0.5506],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.6768, -0.1081, -0.3991,  ..., -0.8560,  0.2349, -1.7395],\n",
      "         [ 0.3681,  2.4369,  0.9258,  ...,  1.3521,  0.6009, -0.8445],\n",
      "         [ 0.9645,  0.2061,  0.6376,  ...,  0.1630, -1.1543, -0.5506],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.6768, -0.1081, -0.3991,  ..., -0.8560,  0.2349, -1.7395],\n",
      "         [-1.5144,  2.3236, -1.2381,  ..., -1.9652, -0.1866, -0.5089],\n",
      "         [ 0.9645,  0.2061,  0.6376,  ...,  0.1630, -1.1543, -0.5506],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.6768, -0.1081, -0.3991,  ..., -0.8560,  0.2349, -1.7395],\n",
      "         [ 0.3704,  1.1248,  0.9187,  ..., -0.5733, -0.5139, -0.5086],\n",
      "         [ 1.0162, -0.2547, -0.7548,  ..., -0.2914,  0.4208,  0.5662],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.6768, -0.1081, -0.3991,  ..., -0.8560,  0.2349, -1.7395],\n",
      "         [ 0.3681,  2.4369,  0.9258,  ...,  1.3521,  0.6009, -0.8445],\n",
      "         [-0.8311,  1.4816,  0.2908,  ...,  0.3143,  1.7242,  1.5950],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.6768, -0.1081, -0.3991,  ..., -0.8560,  0.2349, -1.7395],\n",
      "         [ 0.3681,  2.4369,  0.9258,  ...,  1.3521,  0.6009, -0.8445],\n",
      "         [-0.8311,  1.4816,  0.2908,  ...,  0.3143,  1.7242,  1.5950],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      " \n",
      "미니배치 0의 rnn 결과:\n",
      "torch.Size([512, 19, 64])\n",
      "tensor([[[-0.1281,  0.1210, -0.1607,  ..., -0.0809,  0.1748, -0.2261],\n",
      "         [-0.3698,  0.0914,  0.0408,  ..., -0.3292,  0.2756, -0.4168],\n",
      "         [-0.3226,  0.2305,  0.0461,  ..., -0.1112, -0.0329, -0.3534],\n",
      "         ...,\n",
      "         [-0.0995,  0.1421,  0.1438,  ..., -0.0066,  0.0791,  0.0396],\n",
      "         [-0.0982,  0.1444,  0.1439,  ..., -0.0068,  0.0819,  0.0386],\n",
      "         [-0.0973,  0.1459,  0.1439,  ..., -0.0073,  0.0835,  0.0381]],\n",
      "\n",
      "        [[-0.1281,  0.1210, -0.1607,  ..., -0.0809,  0.1748, -0.2261],\n",
      "         [-0.2997, -0.0083, -0.2722,  ..., -0.1214, -0.3413,  0.1708],\n",
      "         [-0.2861,  0.1410, -0.0819,  ..., -0.0511, -0.2508,  0.0591],\n",
      "         ...,\n",
      "         [-0.0979,  0.1478,  0.1431,  ..., -0.0071,  0.0847,  0.0381],\n",
      "         [-0.0972,  0.1480,  0.1434,  ..., -0.0077,  0.0852,  0.0377],\n",
      "         [-0.0967,  0.1481,  0.1436,  ..., -0.0082,  0.0855,  0.0375]],\n",
      "\n",
      "        [[-0.1281,  0.1210, -0.1607,  ..., -0.0809,  0.1748, -0.2261],\n",
      "         [-0.1091, -0.2418,  0.0694,  ..., -0.1378,  0.3258, -0.2974],\n",
      "         [-0.1730,  0.0272,  0.0652,  ..., -0.0662,  0.0331, -0.2592],\n",
      "         ...,\n",
      "         [-0.0947,  0.1472,  0.1419,  ..., -0.0080,  0.0850,  0.0352],\n",
      "         [-0.0952,  0.1474,  0.1427,  ..., -0.0083,  0.0852,  0.0359],\n",
      "         [-0.0955,  0.1477,  0.1432,  ..., -0.0085,  0.0854,  0.0365]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1281,  0.1210, -0.1607,  ..., -0.0809,  0.1748, -0.2261],\n",
      "         [-0.3567,  0.2821, -0.0905,  ...,  0.0788, -0.3314, -0.1848],\n",
      "         [-0.0282,  0.0062,  0.4178,  ...,  0.0817,  0.2947, -0.1962],\n",
      "         ...,\n",
      "         [-0.0968,  0.1481,  0.1442,  ..., -0.0091,  0.0858,  0.0378],\n",
      "         [-0.0965,  0.1482,  0.1440,  ..., -0.0091,  0.0859,  0.0377],\n",
      "         [-0.0963,  0.1482,  0.1439,  ..., -0.0092,  0.0860,  0.0376]],\n",
      "\n",
      "        [[-0.1281,  0.1210, -0.1607,  ..., -0.0809,  0.1748, -0.2261],\n",
      "         [-0.2997, -0.0083, -0.2722,  ..., -0.1214, -0.3413,  0.1708],\n",
      "         [-0.6541,  0.2098, -0.0808,  ..., -0.2433, -0.4738,  0.1683],\n",
      "         ...,\n",
      "         [-0.1015,  0.1386,  0.1419,  ..., -0.0067,  0.0728,  0.0398],\n",
      "         [-0.0991,  0.1422,  0.1427,  ..., -0.0063,  0.0782,  0.0386],\n",
      "         [-0.0977,  0.1445,  0.1432,  ..., -0.0066,  0.0814,  0.0379]],\n",
      "\n",
      "        [[-0.1281,  0.1210, -0.1607,  ..., -0.0809,  0.1748, -0.2261],\n",
      "         [-0.2997, -0.0083, -0.2722,  ..., -0.1214, -0.3413,  0.1708],\n",
      "         [-0.6541,  0.2098, -0.0808,  ..., -0.2433, -0.4738,  0.1683],\n",
      "         ...,\n",
      "         [-0.0961,  0.1482,  0.1438,  ..., -0.0087,  0.0857,  0.0374],\n",
      "         [-0.0961,  0.1482,  0.1439,  ..., -0.0089,  0.0858,  0.0374],\n",
      "         [-0.0961,  0.1482,  0.1439,  ..., -0.0090,  0.0859,  0.0374]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      " \n",
      "미니배치 0의 y_out:\n",
      "torch.Size([9728, 64])\n",
      "tensor([[-0.1281,  0.1210, -0.1607,  ..., -0.0809,  0.1748, -0.2261],\n",
      "        [-0.3698,  0.0914,  0.0408,  ..., -0.3292,  0.2756, -0.4168],\n",
      "        [-0.3226,  0.2305,  0.0461,  ..., -0.1112, -0.0329, -0.3534],\n",
      "        ...,\n",
      "        [-0.0961,  0.1482,  0.1438,  ..., -0.0087,  0.0857,  0.0374],\n",
      "        [-0.0961,  0.1482,  0.1439,  ..., -0.0089,  0.0858,  0.0374],\n",
      "        [-0.0961,  0.1482,  0.1439,  ..., -0.0090,  0.0859,  0.0374]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      " \n",
      "미니배치 0의 dropout 결과:\n",
      "torch.Size([9728, 88])\n",
      "tensor([[ 8.3400e-02, -1.5268e-01, -2.7140e-01,  ...,  7.4197e-03,\n",
      "          6.3376e-02, -2.5802e-01],\n",
      "        [-2.4455e-02,  5.6923e-02, -1.5041e-01,  ...,  1.5766e-01,\n",
      "         -9.4375e-02, -2.2746e-01],\n",
      "        [-2.2306e-01,  2.6661e-01, -6.1167e-02,  ...,  9.2376e-02,\n",
      "          3.7452e-02, -9.2366e-02],\n",
      "        ...,\n",
      "        [ 2.7931e-02, -2.4421e-02, -7.2149e-02,  ...,  1.0727e-01,\n",
      "          1.3396e-04, -1.9400e-02],\n",
      "        [ 1.4907e-02,  9.1127e-02, -4.4728e-02,  ...,  1.4727e-01,\n",
      "          3.3693e-02, -9.5646e-03],\n",
      "        [ 6.0494e-02,  8.7349e-02, -5.6249e-02,  ...,  7.4376e-02,\n",
      "         -1.7230e-02, -6.7731e-02]], grad_fn=<AddmmBackward0>)\n",
      " \n",
      "미니배치 0의 y_out.shape[-1] 결과:\n",
      "88\n",
      " \n",
      "미니배치 0의 view 결과:\n",
      "torch.Size([512, 19, 88])\n",
      "tensor([[[ 8.3400e-02, -1.5268e-01, -2.7140e-01,  ...,  7.4197e-03,\n",
      "           6.3376e-02, -2.5802e-01],\n",
      "         [-2.4455e-02,  5.6923e-02, -1.5041e-01,  ...,  1.5766e-01,\n",
      "          -9.4375e-02, -2.2746e-01],\n",
      "         [-2.2306e-01,  2.6661e-01, -6.1167e-02,  ...,  9.2376e-02,\n",
      "           3.7452e-02, -9.2366e-02],\n",
      "         ...,\n",
      "         [ 7.8544e-02,  2.3468e-02, -4.8547e-02,  ...,  1.1268e-01,\n",
      "           3.1732e-03, -8.6120e-02],\n",
      "         [ 1.0537e-01,  1.2024e-01, -6.3764e-02,  ...,  1.0506e-01,\n",
      "           3.5383e-02, -1.6271e-02],\n",
      "         [-1.0653e-02,  1.0628e-02,  1.9199e-02,  ...,  1.0362e-02,\n",
      "           4.7140e-02,  2.9666e-02]],\n",
      "\n",
      "        [[ 1.1587e-01,  1.4743e-01, -2.8289e-01,  ...,  1.4030e-01,\n",
      "           2.4980e-01, -2.1380e-01],\n",
      "         [ 1.3423e-01,  4.8628e-02, -5.6868e-03,  ...,  1.2072e-01,\n",
      "          -4.6099e-02,  1.8695e-01],\n",
      "         [-8.1465e-02,  1.2343e-01, -1.2445e-01,  ...,  1.4563e-01,\n",
      "          -6.0631e-02,  6.2212e-02],\n",
      "         ...,\n",
      "         [-2.2858e-02,  2.5040e-02,  1.2053e-04,  ...,  9.9803e-02,\n",
      "           1.9386e-02, -8.8182e-03],\n",
      "         [ 4.3501e-02,  1.4706e-01, -1.0928e-01,  ...,  2.6589e-02,\n",
      "           9.6350e-03, -3.2561e-02],\n",
      "         [ 2.2087e-02,  8.4649e-02, -4.0806e-02,  ...,  1.0331e-02,\n",
      "           6.3895e-02, -4.3948e-02]],\n",
      "\n",
      "        [[ 6.4562e-02,  6.2301e-02, -2.5082e-01,  ..., -3.5506e-01,\n",
      "           9.8781e-02, -3.2958e-01],\n",
      "         [-1.8249e-01,  4.5285e-02, -1.0437e-01,  ..., -1.2145e-02,\n",
      "           7.1729e-02, -1.1176e-01],\n",
      "         [-1.9382e-01,  2.3067e-02,  1.7100e-02,  ...,  2.3624e-02,\n",
      "          -1.0190e-01, -2.2605e-01],\n",
      "         ...,\n",
      "         [ 1.8385e-02,  4.7009e-02, -1.0026e-01,  ...,  2.4471e-02,\n",
      "           1.2104e-01,  1.7538e-02],\n",
      "         [ 5.7173e-02,  1.1597e-01, -4.3168e-02,  ...,  1.0794e-01,\n",
      "           3.1185e-02, -1.5898e-02],\n",
      "         [ 1.0714e-01,  7.7844e-02, -3.4101e-02,  ...,  5.1977e-02,\n",
      "           6.3091e-03, -7.4703e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.3457e-01, -3.8764e-02, -8.3186e-02,  ..., -5.2191e-02,\n",
      "           1.3472e-01, -1.8096e-01],\n",
      "         [-1.3611e-01,  3.7116e-02, -5.4982e-02,  ..., -1.2699e-01,\n",
      "           1.4189e-01,  8.4677e-02],\n",
      "         [-7.9729e-03, -5.5188e-04, -9.6969e-03,  ...,  1.4690e-01,\n",
      "          -2.2883e-01, -2.7479e-02],\n",
      "         ...,\n",
      "         [ 6.0409e-03,  2.4923e-02, -6.8159e-02,  ...,  1.6623e-01,\n",
      "          -1.0818e-01, -4.0259e-02],\n",
      "         [ 2.2606e-02,  1.0149e-01,  4.3587e-02,  ...,  1.0088e-01,\n",
      "          -7.1405e-02,  1.0785e-02],\n",
      "         [-1.3844e-02,  3.3306e-02, -2.3602e-02,  ...,  3.8717e-02,\n",
      "           9.7205e-02,  2.6982e-02]],\n",
      "\n",
      "        [[ 1.0828e-01,  1.3061e-01, -3.2477e-01,  ..., -1.5205e-01,\n",
      "           1.2415e-01, -2.0767e-01],\n",
      "         [ 9.6109e-02,  7.3021e-02, -9.3056e-02,  ...,  7.3722e-02,\n",
      "          -1.4695e-02,  1.0166e-02],\n",
      "         [-2.1204e-01, -4.5952e-02,  5.5323e-02,  ...,  6.9956e-02,\n",
      "           3.5925e-02,  2.0728e-01],\n",
      "         ...,\n",
      "         [ 4.0977e-02,  1.1721e-01,  2.1742e-02,  ...,  4.1819e-02,\n",
      "           3.5625e-02,  1.6155e-02],\n",
      "         [ 3.2070e-02,  3.4053e-02, -4.3782e-03,  ...,  1.2973e-01,\n",
      "           7.1182e-02,  7.7750e-02],\n",
      "         [ 3.9653e-02,  1.7257e-01,  6.8270e-02,  ...,  3.5523e-02,\n",
      "           3.4601e-02, -1.2516e-01]],\n",
      "\n",
      "        [[ 2.4256e-01,  1.1105e-02,  2.1038e-02,  ..., -1.2232e-01,\n",
      "           1.4875e-01, -1.2808e-01],\n",
      "         [-1.7475e-01,  1.1319e-01, -1.5252e-01,  ..., -5.1771e-02,\n",
      "          -1.4232e-02, -7.0758e-03],\n",
      "         [ 1.5285e-01,  3.0208e-01, -1.7368e-01,  ...,  7.8198e-04,\n",
      "           3.3419e-01,  6.6473e-02],\n",
      "         ...,\n",
      "         [ 2.7931e-02, -2.4421e-02, -7.2149e-02,  ...,  1.0727e-01,\n",
      "           1.3396e-04, -1.9400e-02],\n",
      "         [ 1.4907e-02,  9.1127e-02, -4.4728e-02,  ...,  1.4727e-01,\n",
      "           3.3693e-02, -9.5646e-03],\n",
      "         [ 6.0494e-02,  8.7349e-02, -5.6249e-02,  ...,  7.4376e-02,\n",
      "          -1.7230e-02, -6.7731e-02]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "char_vocab_size = len(char_vocab.token_to_idx) \n",
    "char_embedding_size = 32\n",
    "rnn_hidden_size = 64\n",
    "padding_idx=0\n",
    "batch_first=True\n",
    "\n",
    "\n",
    "emb = nn.Embedding(num_embeddings = char_vocab_size,\n",
    "                           embedding_dim = char_embedding_size,\n",
    "                           padding_idx = padding_idx)\n",
    "        \n",
    "rnn = nn.GRU(input_size=char_embedding_size, \n",
    "              hidden_size=rnn_hidden_size,\n",
    "              batch_first=batch_first)\n",
    "\n",
    "fc = nn.Linear(in_features=rnn_hidden_size, \n",
    "                out_features=char_vocab_size)\n",
    "    \n",
    "\n",
    "# 데이터 로더에서 미니배치를 반복합니다.\n",
    "for batch_index, batch in enumerate(Traindataloader):\n",
    "    # 각 미니배치에서 샘플을 가져옵니다.\n",
    "    x_in = batch['x_data']\n",
    "    y_in = batch['y_target']\n",
    "    \n",
    "    \n",
    "    embedded_sample = emb(x_in)\n",
    "    \n",
    "    # 임베딩 결과를 출력합니다.\n",
    "    print(f\"미니배치 {batch_index}의 임베딩 결과:\")\n",
    "    print(embedded_sample.size())\n",
    "    print(embedded_sample)\n",
    "    \n",
    "    y_out, _ = rnn(embedded_sample)\n",
    "    \n",
    "    \n",
    "    print(\" \")\n",
    "    print(f\"미니배치 {batch_index}의 rnn 결과:\")\n",
    "    print(y_out.size())\n",
    "    print(y_out)\n",
    "    \n",
    "    batch_size, seq_size, feat_size = y_out.shape\n",
    "    y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
    "    \n",
    "    print(\" \")\n",
    "    print(f\"미니배치 {batch_index}의 y_out:\")\n",
    "    print(y_out.size())\n",
    "    print(y_out)\n",
    "    \n",
    "    y_out = fc(F.dropout(y_out, p=0.5))\n",
    "    \n",
    "    print(\" \")\n",
    "    print(f\"미니배치 {batch_index}의 dropout 결과:\")\n",
    "    print(y_out.size())\n",
    "    print(y_out)\n",
    "    \n",
    "    new_feat_size = y_out.shape[-1]\n",
    "    print(\" \")\n",
    "    print(f\"미니배치 {batch_index}의 y_out.shape[-1] 결과:\")\n",
    "    print(new_feat_size)  # 88\n",
    "\n",
    "    \n",
    "    y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
    "    print(\" \")\n",
    "    print(f\"미니배치 {batch_index}의 view 결과:\")\n",
    "    print(y_out.size())\n",
    "    print(y_out)\n",
    "        \n",
    "        \n",
    "#     y_pred = y_out\n",
    "#     loss =  loss_func(y_pred, y_in)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d622c",
   "metadata": {},
   "source": [
    "### 옵티마이저, loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "330f6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b5517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 옵티마이저\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a88fc42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sizes(y_pred, y_true):\n",
    "    \"\"\"\n",
    "        y_pred (torch.Tensor): 모델의 출력\n",
    "            3차원 텐서이면 행렬로 변환합니다.\n",
    "        y_true (torch.Tensor): 타깃 예측\n",
    "            행렬이면 벡터로 변환합니다.\n",
    "    \"\"\"\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b56190b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dedc2b",
   "metadata": {},
   "source": [
    "## normalize_sizes 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6b2cc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred tensor([[0.1000, 0.9000],\n",
      "        [0.8000, 0.2000],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.6000, 0.4000]])\n",
      "y_true tensor([1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# normalize_sizes 함수 정의\n",
    "def normalize_sizes(y_pred, y_true):\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "# 예측값과 실제값 생성 (예시)\n",
    "y_pred = torch.tensor([[[0.1, 0.9], [0.8, 0.2]], [[0.3, 0.7], [0.6, 0.4]]])\n",
    "y_true = torch.tensor([[1, 0], [0, 1]])\n",
    "\n",
    "# 손실 함수 계산을 위해 normalize_sizes 함수 적용\n",
    "y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "print(\"y_pred\",y_pred)\n",
    "print(\"y_true\",y_true)\n",
    "\n",
    "# # 손실 함수 계산\n",
    "# loss = F.cross_entropy(y_pred, y_true)\n",
    "\n",
    "# print(\"손실 함수 값:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3781e8c8",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e515293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float() #마스킹 안된 것만 유효 index로 정의\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8427c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train state 초기화 \n",
    "def make_train_state():\n",
    "    return {\n",
    "        'stop_early':False,\n",
    "        'early_stopping_step':0,\n",
    "        'early_stopping_best_val':1e8,\n",
    "        'early_stopping_criteria' : 10,\n",
    "        'epoch_index' : 0,\n",
    "        'train_loss': [], \n",
    "        'train_acc' :[], \n",
    "        'val_loss' : [],\n",
    "        'val_acc' : [], \n",
    "        'test_loss' : [],\n",
    "        'test_acc' : [],\n",
    "         \n",
    "#       모델 저장파일\n",
    "        'model_filename' : 'model.pth'\n",
    "    } \n",
    "\n",
    "\n",
    "# Train update \n",
    "def update_train_state(model, train_state):\n",
    "    \n",
    "#   학습시작하면 초기에 모델 저장하기 \n",
    "    \n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(),train_state['model_filename'])\n",
    "        \n",
    "#   모델 성능이 향상되면 모델 저장(valid loss가 더 낮아지면)\n",
    "    elif train_state['epoch_index'] >=1 :\n",
    "        loss_t = train_state['val_loss'][-1]\n",
    "#        loss가 나빠지면 early stop step 업데이트\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            train_state['early_stopping_step']+=1\n",
    "            \n",
    "#        loss가 좋아지면   \n",
    "        else:\n",
    "#            early stop step 0으로 다시 초기화        \n",
    "            train_state['early_stopping_step']=0\n",
    "    \n",
    "#           최저 loss이면 모델 저장 \n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "                torch.save(model.state_dict(),train_state['model_filename'])\n",
    "\n",
    "#       기준점 넘으면 early stop \n",
    "        if train_state['early_stopping_step'] >= train_state['early_stopping_criteria']:\n",
    "            train_state['stop_early'] = True\n",
    "        \n",
    "        return train_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87458bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_early': False,\n",
       " 'early_stopping_step': 0,\n",
       " 'early_stopping_best_val': 100000000.0,\n",
       " 'early_stopping_criteria': 10,\n",
       " 'epoch_index': 0,\n",
       " 'train_loss': [],\n",
       " 'train_acc': [],\n",
       " 'val_loss': [],\n",
       " 'val_acc': [],\n",
       " 'test_loss': [],\n",
       " 'test_acc': [],\n",
       " 'model_filename': 'model.pth'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 진행 상황 함수 초기화\n",
    "train_state = make_train_state()\n",
    "train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "550eb7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                          | 1/100 [00:01<01:46,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 4.338480790456136\n",
      "val_acc 3.571173238759035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                          | 2/100 [00:02<01:44,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 4.03706423441569\n",
      "val_acc 6.031034312102194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▎                                         | 3/100 [00:03<01:38,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 3.5977984269460044\n",
      "val_acc 6.727069450698828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▋                                         | 4/100 [00:04<01:37,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 3.34366774559021\n",
      "val_acc 11.192793862357634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██▏                                        | 5/100 [00:05<01:44,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 3.2401487827301025\n",
      "val_acc 13.753772314946723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▌                                        | 6/100 [00:06<01:40,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 3.17496657371521\n",
      "val_acc 15.113712079552988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|███                                        | 7/100 [00:07<01:39,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 3.116319179534912\n",
      "val_acc 16.14586598483967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▍                                       | 8/100 [00:08<01:37,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 3.0664554437001548\n",
      "val_acc 17.00798293737608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▊                                       | 9/100 [00:09<01:42,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 3.027183771133423\n",
      "val_acc 17.5762851541794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▏                                     | 10/100 [00:10<01:38,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.9928225676218667\n",
      "val_acc 18.336815574030105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▌                                     | 11/100 [00:11<01:36,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.9631017049153647\n",
      "val_acc 18.417614312445465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████                                     | 12/100 [00:12<01:35,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.9487913449605307\n",
      "val_acc 18.572449588932653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████▍                                    | 13/100 [00:14<01:35,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.929863691329956\n",
      "val_acc 18.58534787877949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▉                                    | 14/100 [00:15<01:32,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.9179724057515464\n",
      "val_acc 19.08209421005182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▎                                   | 15/100 [00:16<01:29,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.902268568674723\n",
      "val_acc 19.358338036378132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████▋                                   | 16/100 [00:17<01:28,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8942235310872397\n",
      "val_acc 19.110822358891692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████▏                                  | 17/100 [00:18<01:26,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8841446240743003\n",
      "val_acc 19.123605735181307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████▌                                  | 18/100 [00:19<01:27,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.883004347483317\n",
      "val_acc 19.190782645675124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████▉                                  | 19/100 [00:20<01:30,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8709401289621987\n",
      "val_acc 19.409990873955028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▍                                 | 20/100 [00:21<01:27,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8671154181162515\n",
      "val_acc 19.52571277191273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████▊                                 | 21/100 [00:22<01:28,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8499996662139893\n",
      "val_acc 19.463957820660113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████▏                                | 22/100 [00:23<01:24,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8508729139963784\n",
      "val_acc 19.332606371946675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████▋                                | 23/100 [00:24<01:25,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8507049878438315\n",
      "val_acc 19.398504026242794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████                                | 24/100 [00:25<01:21,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.847710688908895\n",
      "val_acc 19.71851742392217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██████████▌                               | 25/100 [00:27<01:27,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8415218194325766\n",
      "val_acc 19.60734698328811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██████████▉                               | 26/100 [00:28<01:22,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.840250571568807\n",
      "val_acc 19.660589030492744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████▎                              | 27/100 [00:29<01:21,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.836102326711019\n",
      "val_acc 19.609267167167992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████▊                              | 28/100 [00:30<01:20,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8380130926767984\n",
      "val_acc 19.46621071192484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████▏                             | 29/100 [00:31<01:15,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.834988594055176\n",
      "val_acc 19.863904901665837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████▌                             | 30/100 [00:32<01:12,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8341036637624106\n",
      "val_acc 19.63281454054676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████                             | 31/100 [00:33<01:10,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8288962046305337\n",
      "val_acc 19.434850527000723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████▍                            | 32/100 [00:34<01:09,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8313562870025635\n",
      "val_acc 19.61444231273554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████▊                            | 33/100 [00:35<01:09,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8309008280436196\n",
      "val_acc 19.790272187458292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████▎                           | 34/100 [00:36<01:10,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8258833090464273\n",
      "val_acc 19.71260708975842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|██████████████▋                           | 35/100 [00:37<01:08,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8300113677978516\n",
      "val_acc 19.915663237624766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███████████████                           | 36/100 [00:38<01:08,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8294379711151123\n",
      "val_acc 19.97507863688726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███████████████▌                          | 37/100 [00:39<01:05,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8261839548746743\n",
      "val_acc 19.683996904020407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████▉                          | 38/100 [00:40<01:03,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.822040637334188\n",
      "val_acc 19.768650793842685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|████████████████▍                         | 39/100 [00:41<01:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.821429173151652\n",
      "val_acc 19.661931062596945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████▊                         | 40/100 [00:42<01:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8205695947011313\n",
      "val_acc 19.874470435224556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████▏                        | 41/100 [00:43<01:01,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8208481470743814\n",
      "val_acc 19.78664915404898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████▋                        | 42/100 [00:44<01:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8189258575439453\n",
      "val_acc 19.68589204665957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████                        | 43/100 [00:45<01:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8229783376057944\n",
      "val_acc 19.89131576260042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████▍                       | 44/100 [00:47<01:01,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8183223406473794\n",
      "val_acc 19.774457397321605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|██████████████████▉                       | 45/100 [00:48<00:58,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8187952836354575\n",
      "val_acc 20.064061898670317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|███████████████████▎                      | 46/100 [00:49<01:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.815053860346476\n",
      "val_acc 19.98252765369282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████▋                      | 47/100 [00:50<01:01,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.815638542175293\n",
      "val_acc 19.99134385072527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████████████████████▏                     | 48/100 [00:51<00:57,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8174219131469727\n",
      "val_acc 19.863510030244573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████████████████████▌                     | 49/100 [00:52<00:54,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8171549638112388\n",
      "val_acc 20.16505461374033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████                     | 50/100 [00:53<00:52,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.811586062113444\n",
      "val_acc 20.01267133200839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████████████████████▍                    | 51/100 [00:54<00:50,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.815774838129679\n",
      "val_acc 19.811902703422096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████▊                    | 52/100 [00:55<00:50,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8127740224202475\n",
      "val_acc 20.200689927426854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████▎                   | 53/100 [00:57<00:54,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8114918073018393\n",
      "val_acc 20.03608629247736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████▋                   | 54/100 [00:58<00:53,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8117194175720215\n",
      "val_acc 20.037731557478182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████                   | 55/100 [00:59<00:57,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.81473700205485\n",
      "val_acc 19.844138621318574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|███████████████████████▌                  | 56/100 [01:00<00:53,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8089207808176675\n",
      "val_acc 19.787784076929924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████▉                  | 57/100 [01:02<00:50,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8120240370432534\n",
      "val_acc 19.705099045670107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████▎                 | 58/100 [01:03<00:48,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8101742267608643\n",
      "val_acc 20.083776248166426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████▊                 | 59/100 [01:04<00:46,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8147141138712564\n",
      "val_acc 19.766063863976058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████▏                | 60/100 [01:05<00:43,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8055564562479653\n",
      "val_acc 20.047123730730117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|█████████████████████████▌                | 61/100 [01:06<00:41,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8102962176005044\n",
      "val_acc 19.87765890768293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████                | 62/100 [01:07<00:39,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.811798175175985\n",
      "val_acc 20.117200487714157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████▍               | 63/100 [01:08<00:37,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.808818737665812\n",
      "val_acc 20.09970075867353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████▉               | 64/100 [01:09<00:37,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.811549107233683\n",
      "val_acc 20.120360106392315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████▎              | 65/100 [01:10<00:37,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.810814460118612\n",
      "val_acc 19.813665836870637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|███████████████████████████▋              | 66/100 [01:11<00:39,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.810210386912028\n",
      "val_acc 19.856039839495082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████▏             | 67/100 [01:12<00:37,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8090453147888184\n",
      "val_acc 20.231247010381864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|████████████████████████████▌             | 68/100 [01:13<00:35,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.808390220006307\n",
      "val_acc 19.954277413450164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████▉             | 69/100 [01:15<00:35,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8096299966176352\n",
      "val_acc 19.90861066379202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████▉             | 69/100 [01:16<00:34,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 2.8064301013946533\n",
      "val_acc 20.032327534671822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "mask_index = char_vocab.mask_index\n",
    "\n",
    "# 에포크만큼\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "\n",
    "#     print('epoch',epoch)\n",
    "#     print(train_state['epoch_index']) \n",
    "    train_state['epoch_index'] +=1 \n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "\n",
    "#     모델을 학습 모드로 설정 -> 드롭아웃 및 배치 정규화와 같은 학습 중에만 적용되는 기법들이 활성화\n",
    "#     모델을 평가 모드로 전환하려면 model.eval()을 사용\n",
    "    model.train()\n",
    "# 배치 만큼\n",
    "    for batch_idx, batch_data in enumerate(Traindataloader):\n",
    "        \n",
    "\n",
    "#       1. 옵티마이저 그레디언트 0으로 초기화\n",
    "        optimizer.zero_grad()\n",
    "#       2. 모델에 데이터 넣어서 출력받기\n",
    "        y_pred = model(x_in=batch_data['x_data'])\n",
    "#       3. loss 계산하기\n",
    "        loss =  sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "\n",
    "    \n",
    "#       4. gradient 계산하기\n",
    "        loss.backward()\n",
    "\n",
    "#       5. 옵티마이저 가중치 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "#       Accuracy 계산\n",
    "        # 이동 손실과 이동 정확도를 계산\n",
    "        running_loss += (loss.item() - running_loss) / (batch_idx + 1)\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "        running_acc += (acc_t - running_acc) / (batch_idx + 1)\n",
    "\n",
    "\n",
    "    train_state['train_loss'].append(running_loss)\n",
    "    train_state['train_acc'].append(running_acc)\n",
    "\n",
    "\n",
    "#   valid에 대한 계산\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "    model.eval() # 모델 파라미터를 수정하지 못 하게 비활성화\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(Validdataloader):\n",
    "\n",
    "#       1. 모델의 출력값(y_pred)계산\n",
    "        y_pred = model(x_in=batch_data['x_data'])\n",
    "\n",
    "#       2. loss 계산\n",
    "        loss_t = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "        running_loss += (loss_t.item() - running_loss) / (batch_idx + 1)\n",
    "\n",
    "#       3. Accuracy 계산\n",
    "        acc_t = compute_accuracy(y_pred,batch_data['y_target'],mask_index)\n",
    "        running_acc += (acc_t - running_acc) / (batch_idx + 1)\n",
    "    \n",
    "    print(\"val_loss\",running_loss)\n",
    "    print(\"val_acc\",running_acc)\n",
    "\n",
    "    train_state['val_loss'].append(running_loss)\n",
    "    train_state['val_acc'].append(running_acc)\n",
    "    \n",
    "\n",
    "#   전체 loss, acc 저장\n",
    "    train_state = update_train_state(model=model,\n",
    "                                     train_state=train_state)\n",
    "#   early stop해라고 했으면 학습 멈추기    \n",
    "    if train_state['stop_early']:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81148c1c",
   "metadata": {},
   "source": [
    "### Test 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c570a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델을 사용해 테스트 세트의 손실과 정확도를 계산합니다\n",
    "\n",
    "model.load_state_dict(torch.load(train_state['model_filename']))\n",
    "\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "\n",
    "# 가중치 업데이트 하지 못 하게\n",
    "model.eval()\n",
    "\n",
    "for batch_idx, batch_data in enumerate(Testdataloader):\n",
    "    \n",
    "    y_pred = model(x_in=batch_data['x_data'])\n",
    "    loss = sequence_loss(y_pred,batch_data['y_target'],mask_index)\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_idx + 1)\n",
    "    \n",
    "    acc_t = compute_accuracy(y_pred, batch_data['y_target'],mask_index)\n",
    "    running_acc += (acc_t - running_acc) / (batch_idx + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4576ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 손실: 2.836\n",
      "테스트 정확도: 20.25\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 손실: {:.3f}\".format(train_state['test_loss']))\n",
    "print(\"테스트 정확도: {:.2f}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501556c",
   "metadata": {},
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "900253cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_samples(sampled_indices):\n",
    "    \"\"\"인덱스를 성씨 문자열로 바꿈\n",
    "    \"\"\"\n",
    "    decoded_surnames = []\n",
    "    vocab = char_vocab\n",
    "    \n",
    "    for sample_index in range(sampled_indices.shape[0]):\n",
    "        surname = \"\"\n",
    "        for time_step in range(sampled_indices.shape[1]):\n",
    "            sample_item = sampled_indices[sample_index, time_step].item()\n",
    "            if sample_item == vocab.begin_seq_index:\n",
    "                continue\n",
    "            elif sample_item == vocab.end_seq_index:\n",
    "                break\n",
    "            else:\n",
    "                surname += lookup_index(vocab,sample_item)\n",
    "        decoded_surnames.append(surname)\n",
    "    return decoded_surnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "079c2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(model, num_samples=1, sample_size=20, \n",
    "                      temperature=1.0):\n",
    "    \"\"\"모델이 만든 인덱스 시퀀스를 샘플링\n",
    "    \n",
    "    매개변수:\n",
    "        model (SurnameGenerationModel): 훈련 모델\n",
    "        num_samples (int): 샘플 개수\n",
    "        sample_size (int): 샘플의 최대 길이\n",
    "        temperature (float): 무작위성 정도\n",
    "            0.0 < temperature < 1.0 이면 최대 값을 선택할 가능성이 높습니다\n",
    "            temperature > 1.0 이면 균등 분포에 가깝습니다\n",
    "    반환값:\n",
    "        indices (torch.Tensor): 인덱스 행렬\n",
    "        shape = (num_samples, sample_size)\n",
    "    \"\"\"\n",
    "    begin_seq_index = [char_vocab.begin_seq_index \n",
    "                       for _ in range(num_samples)]\n",
    "    begin_seq_index = torch.tensor(begin_seq_index, \n",
    "                                   dtype=torch.int64).unsqueeze(dim=1)\n",
    "    indices = [begin_seq_index]\n",
    "    h_t = None\n",
    "    \n",
    "    for time_step in range(sample_size):\n",
    "        x_t = indices[time_step]\n",
    "        x_emb_t = model.emb(x_t)\n",
    "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n",
    "        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\n",
    "        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\n",
    "        indices.append(torch.multinomial(probability_vector, num_samples=1))\n",
    "    indices = torch.stack(indices).squeeze().permute(1, 0)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4dc3563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Hhurnv\n",
      "Wookico\n",
      "Fasttilo\n",
      "ñslseswa\n",
      "Kaavi\n",
      "Kooosuhta\n",
      "Taouluannvo\n",
      "Yhontade\n",
      "Dozas\n",
      "Ssle\n"
     ]
    }
   ],
   "source": [
    "# 생성할 이름 개수\n",
    "num_names = 10\n",
    "model = model.cpu()\n",
    "# 이름 생성\n",
    "sampled_surnames = decode_samples(\n",
    "    sample_from_model(model, num_samples=num_names))\n",
    "# 결과 출력\n",
    "print (\"-\"*15)\n",
    "for i in range(num_names):\n",
    "    print (sampled_surnames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae713163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7db462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
